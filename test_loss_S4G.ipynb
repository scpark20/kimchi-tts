{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_S4G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 19 12:55:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:2E:00.0 Off |                  N/A |\n",
      "| 44%   61C    P0    96W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |\n",
      "| 26%   50C    P0    46W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/model_S4G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_100667  save_61887  save_75000  save_90000\r\n",
      "save_100000  save_102025  save_65000  save_80000  save_95000\r\n",
      "save_100096  save_400000  save_70000  save_85000  save_96091\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 243.8MiB\n",
      "TTS size 156.2MiB\n",
      "MelDecoder size 94.9MiB\n",
      "loaded : 400000\n",
      "400000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 400000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7efb7098eb50>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7efb70d51fd0>\n"
     ]
    }
   ],
   "source": [
    "trainset = LJDataset(tts_hparams, split='train')\n",
    "testset = LJDataset(tts_hparams, split='valid')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, num_workers=1, #tts_hparams.num_workers, \n",
    "                          shuffle=True, sampler=None, batch_size=tts_hparams.batch_size, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(train_loader)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.022382887080311775\n",
      "1 0.023449862375855446\n",
      "2 0.025559375062584877\n",
      "3 0.022370530292391777\n",
      "4 0.02345271222293377\n",
      "5 0.023348787799477577\n",
      "6 0.023410581052303314\n",
      "7 0.021123075857758522\n",
      "8 0.022145019844174385\n",
      "9 0.022328414022922516\n",
      "10 0.02523878403007984\n",
      "11 0.025300167500972748\n",
      "12 0.023659462109208107\n",
      "13 0.02310110256075859\n",
      "14 0.02213812991976738\n",
      "15 0.024974577128887177\n",
      "16 0.024835029616951942\n",
      "17 0.023937776684761047\n",
      "18 0.025353282690048218\n",
      "19 0.02510518953204155\n",
      "20 0.021854959428310394\n",
      "21 0.022878659889101982\n",
      "22 0.021198203787207603\n",
      "23 0.024732433259487152\n",
      "24 0.02315761335194111\n",
      "25 0.026018014177680016\n",
      "26 0.02376648783683777\n",
      "27 0.023244759067893028\n",
      "28 0.023344721645116806\n",
      "29 0.024323996156454086\n",
      "30 0.024355165660381317\n",
      "31 0.02530411258339882\n",
      "32 0.024242132902145386\n",
      "33 0.023628029972314835\n",
      "34 0.02310008555650711\n",
      "35 0.024252530187368393\n",
      "36 0.023968582972884178\n",
      "37 0.023101666942238808\n",
      "38 0.02426758036017418\n",
      "39 0.022403167560696602\n",
      "40 0.0250279288738966\n",
      "41 0.024806970730423927\n",
      "42 0.02300349436700344\n",
      "43 0.025066345930099487\n",
      "44 0.023035380989313126\n",
      "45 0.02552999183535576\n",
      "46 0.021993661299347878\n",
      "47 0.023643197491765022\n",
      "48 0.02286977879703045\n",
      "49 0.023221813142299652\n",
      "50 0.022875217720866203\n",
      "51 0.021880464628338814\n",
      "52 0.022066589444875717\n",
      "53 0.02438708208501339\n",
      "54 0.023345421999692917\n",
      "55 0.024474231526255608\n",
      "56 0.02268259786069393\n",
      "57 0.022966327145695686\n",
      "58 0.023130565881729126\n",
      "59 0.024294177070260048\n",
      "60 0.020152848213911057\n",
      "61 0.022715073078870773\n",
      "62 0.024214213714003563\n",
      "63 0.022583844140172005\n",
      "64 0.022946909070014954\n",
      "65 0.023559823632240295\n",
      "66 0.02268250100314617\n",
      "67 0.024895427748560905\n",
      "68 0.026106415316462517\n",
      "69 0.027080345898866653\n",
      "70 0.023403670638799667\n",
      "71 0.02676115185022354\n",
      "72 0.0246382188051939\n",
      "73 0.0241691954433918\n",
      "74 0.02222559228539467\n",
      "75 0.024827169254422188\n",
      "76 0.024252833798527718\n",
      "77 0.02630261890590191\n",
      "78 0.027366939932107925\n",
      "79 0.025039328262209892\n",
      "80 0.02401425689458847\n",
      "81 0.022071046754717827\n",
      "82 0.025958478450775146\n",
      "83 0.022884557023644447\n",
      "84 0.023884423077106476\n",
      "85 0.025115925818681717\n",
      "86 0.023807654157280922\n",
      "87 0.024111641570925713\n",
      "88 0.022508081048727036\n",
      "89 0.024044910445809364\n",
      "90 0.023603394627571106\n",
      "91 0.02554934471845627\n",
      "92 0.025121323764324188\n",
      "93 0.02435876429080963\n",
      "94 0.022918879985809326\n",
      "95 0.023969415575265884\n",
      "96 0.0243502426892519\n",
      "97 0.02397177182137966\n",
      "98 0.023665573447942734\n",
      "99 0.024823013693094254\n",
      "100 0.022769933566451073\n",
      "101 0.022995537146925926\n",
      "102 0.024101005867123604\n",
      "103 0.023574281483888626\n",
      "104 0.023684119805693626\n",
      "105 0.024690281599760056\n",
      "106 0.023704348132014275\n",
      "107 0.024486346170306206\n",
      "108 0.024010343477129936\n",
      "109 0.023479953408241272\n",
      "110 0.024056097492575645\n",
      "111 0.02533641830086708\n",
      "112 0.0254628024995327\n",
      "113 0.025428587570786476\n",
      "114 0.02445843257009983\n",
      "115 0.02383933588862419\n",
      "116 0.02348250523209572\n",
      "117 0.022945011034607887\n",
      "118 0.022225018590688705\n",
      "119 0.02386053279042244\n",
      "120 0.022375836968421936\n",
      "121 0.025188129395246506\n",
      "122 0.022400027140975\n",
      "123 0.02459532395005226\n",
      "124 0.021431267261505127\n",
      "125 0.022236475721001625\n",
      "126 0.02616828680038452\n",
      "127 0.02282770536839962\n",
      "128 0.024010105058550835\n",
      "129 0.022763581946492195\n",
      "130 0.023121433332562447\n",
      "131 0.022776203230023384\n",
      "132 0.022894416004419327\n",
      "133 0.02244929037988186\n",
      "134 0.023929104208946228\n",
      "135 0.02560526132583618\n",
      "136 0.021861081942915916\n",
      "137 0.024686502292752266\n",
      "138 0.02029094658792019\n",
      "139 0.024960823357105255\n",
      "140 0.026038257405161858\n",
      "141 0.023084966465830803\n",
      "142 0.022120648995041847\n",
      "143 0.024188989773392677\n",
      "144 0.022480323910713196\n",
      "145 0.024072837084531784\n",
      "146 0.02374250255525112\n",
      "147 0.0238480307161808\n",
      "148 0.025488730520009995\n",
      "149 0.02314002253115177\n",
      "150 0.02243361622095108\n",
      "151 0.024995455518364906\n",
      "152 0.024994485080242157\n",
      "153 0.024113383144140244\n",
      "154 0.023813985288143158\n",
      "155 0.024915490299463272\n",
      "156 0.02553008496761322\n",
      "157 0.02520090900361538\n",
      "158 0.02304130420088768\n",
      "159 0.022076012566685677\n",
      "160 0.0227237306535244\n",
      "161 0.022996000945568085\n",
      "162 0.021583177149295807\n",
      "163 0.025040309876203537\n",
      "164 0.025477105751633644\n",
      "165 0.022129913792014122\n",
      "166 0.025910263881087303\n",
      "167 0.026248740032315254\n",
      "168 0.023605192080140114\n",
      "169 0.02442592941224575\n",
      "170 0.025011219084262848\n",
      "171 0.024390283972024918\n",
      "172 0.025515979155898094\n",
      "173 0.024803288280963898\n",
      "174 0.026543864980340004\n",
      "175 0.022987449541687965\n",
      "176 0.023454731330275536\n",
      "177 0.02319543994963169\n",
      "178 0.022739456966519356\n",
      "179 0.023251503705978394\n",
      "180 0.02229912392795086\n",
      "181 0.022915860638022423\n",
      "182 0.024690864607691765\n",
      "183 0.0223651472479105\n",
      "184 0.02504993975162506\n",
      "185 0.022230705246329308\n",
      "186 0.02348199486732483\n",
      "187 0.02222924493253231\n",
      "188 0.02361762709915638\n",
      "189 0.02520219050347805\n",
      "190 0.024098822847008705\n",
      "191 0.02812149003148079\n",
      "192 0.02528701163828373\n",
      "193 0.023942917585372925\n",
      "194 0.022631367668509483\n",
      "195 0.020501822233200073\n",
      "196 0.025322526693344116\n",
      "197 0.025819087401032448\n",
      "198 0.024858521297574043\n",
      "199 0.023196030408143997\n",
      "200 0.022417733445763588\n",
      "201 0.022557007148861885\n",
      "202 0.024848053231835365\n",
      "203 0.024336334317922592\n",
      "204 0.02345803752541542\n",
      "205 0.02431965433061123\n",
      "206 0.024668697267770767\n",
      "207 0.023857077583670616\n",
      "208 0.0247189924120903\n",
      "209 0.021485624834895134\n",
      "210 0.023230915889143944\n",
      "211 0.023294705897569656\n",
      "212 0.02598140947520733\n",
      "213 0.022723820060491562\n",
      "214 0.023101817816495895\n",
      "215 0.024026216939091682\n",
      "216 0.024185910820961\n",
      "217 0.02304399199783802\n",
      "218 0.0253080353140831\n",
      "219 0.021575042977929115\n",
      "220 0.02251865528523922\n",
      "221 0.022124968469142914\n",
      "222 0.024551639333367348\n",
      "223 0.024233320727944374\n",
      "224 0.021285342052578926\n",
      "225 0.024638548493385315\n",
      "226 0.024505652487277985\n",
      "227 0.023457897827029228\n",
      "228 0.02538473531603813\n",
      "229 0.022378992289304733\n",
      "230 0.025781232863664627\n",
      "231 0.021666783839464188\n",
      "232 0.023978834971785545\n",
      "233 0.02226066403090954\n",
      "234 0.024601871147751808\n",
      "235 0.02275029569864273\n",
      "236 0.0228112880140543\n",
      "237 0.02138303779065609\n",
      "238 0.022140517830848694\n",
      "239 0.023537011817097664\n",
      "240 0.022488180547952652\n",
      "241 0.021918106824159622\n",
      "242 0.02455359511077404\n",
      "243 0.024726131930947304\n",
      "244 0.022196494042873383\n",
      "245 0.02501366101205349\n",
      "246 0.024965886026620865\n",
      "247 0.021231962367892265\n",
      "248 0.022434383630752563\n",
      "249 0.024417554959654808\n",
      "250 0.022310901433229446\n",
      "251 0.023195207118988037\n",
      "252 0.02255781553685665\n",
      "253 0.023763226345181465\n",
      "254 0.02423347532749176\n",
      "255 0.02328723669052124\n",
      "256 0.025468679144978523\n",
      "257 0.023622658103704453\n",
      "258 0.023386657238006592\n",
      "259 0.023092830553650856\n",
      "260 0.02104020304977894\n",
      "261 0.024722475558519363\n",
      "262 0.023365257307887077\n",
      "263 0.02487373724579811\n",
      "264 0.020106296986341476\n",
      "265 0.023570677265524864\n",
      "266 0.02261888049542904\n",
      "267 0.02364962548017502\n",
      "268 0.02538750134408474\n",
      "269 0.025661371648311615\n",
      "270 0.02478884346783161\n",
      "271 0.022272763773798943\n",
      "272 0.026080673560500145\n",
      "273 0.024860097095370293\n",
      "274 0.023421760648489\n",
      "275 0.022470474243164062\n",
      "276 0.025097515434026718\n",
      "277 0.02445206046104431\n",
      "278 0.022185755893588066\n",
      "279 0.022990912199020386\n",
      "280 0.025377534329891205\n",
      "281 0.025101255625486374\n",
      "282 0.021480686962604523\n",
      "283 0.02413223683834076\n",
      "284 0.023918939754366875\n",
      "285 0.021577559411525726\n",
      "286 0.022297006100416183\n",
      "287 0.02515161596238613\n",
      "288 0.025616567581892014\n",
      "289 0.024933714419603348\n",
      "290 0.024693593382835388\n",
      "291 0.024325236678123474\n",
      "292 0.022861842066049576\n",
      "293 0.024879639968276024\n",
      "294 0.023280540481209755\n",
      "295 0.020386196672916412\n",
      "296 0.02389870397746563\n",
      "297 0.02293977700173855\n",
      "298 0.02151496894657612\n",
      "299 0.025401843711733818\n",
      "300 0.024409789592027664\n",
      "301 0.02643134817481041\n",
      "302 0.023581016808748245\n",
      "303 0.021182790398597717\n",
      "304 0.024840567260980606\n",
      "305 0.023665813729166985\n",
      "306 0.024566732347011566\n",
      "307 0.023824632167816162\n",
      "308 0.021879933774471283\n",
      "309 0.024338800460100174\n",
      "310 0.024331210181117058\n",
      "311 0.023765122517943382\n",
      "312 0.02391240932047367\n",
      "313 0.022760551422834396\n",
      "314 0.02359219640493393\n",
      "315 0.02287609688937664\n",
      "316 0.02352844923734665\n",
      "317 0.02373545989394188\n",
      "318 0.02151588909327984\n",
      "319 0.02438192628324032\n",
      "320 0.022466018795967102\n",
      "321 0.023772666230797768\n",
      "322 0.02569146826863289\n",
      "323 0.02460007555782795\n",
      "324 0.02535916306078434\n",
      "325 0.02540372870862484\n",
      "326 0.022366220131516457\n",
      "327 0.022881515324115753\n",
      "328 0.023466818034648895\n",
      "329 0.023934008553624153\n",
      "330 0.02228405885398388\n",
      "331 0.02407870441675186\n",
      "332 0.024403603747487068\n",
      "333 0.023368148133158684\n",
      "334 0.0223062876611948\n",
      "335 0.02287682518362999\n",
      "336 0.0215999037027359\n",
      "337 0.023735322058200836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 0.025207098573446274\n",
      "339 0.02434537000954151\n",
      "340 0.022503377869725227\n",
      "341 0.023177873343229294\n",
      "342 0.024008246138691902\n",
      "343 0.021935803815722466\n",
      "344 0.023487508296966553\n",
      "345 0.02543039247393608\n",
      "346 0.024731161072850227\n",
      "347 0.0256471149623394\n",
      "348 0.02332654967904091\n",
      "349 0.022623606026172638\n",
      "350 0.021224310621619225\n",
      "351 0.022512972354888916\n",
      "352 0.021250782534480095\n",
      "353 0.022557398304343224\n",
      "354 0.022394316270947456\n",
      "355 0.025877567008137703\n",
      "356 0.02083621546626091\n",
      "357 0.02211798168718815\n",
      "358 0.023378843441605568\n",
      "359 0.024565227329730988\n",
      "360 0.021742798388004303\n",
      "361 0.02292608842253685\n",
      "362 0.023887598887085915\n",
      "363 0.02292718179523945\n",
      "364 0.023267745971679688\n",
      "365 0.023426825180649757\n",
      "366 0.022565539926290512\n",
      "367 0.023529935628175735\n",
      "368 0.02575341798365116\n",
      "369 0.025642869994044304\n",
      "370 0.022154318168759346\n",
      "371 0.023595545440912247\n",
      "372 0.024525586515665054\n",
      "373 0.02134658396244049\n",
      "374 0.02236410416662693\n",
      "375 0.026104576885700226\n",
      "376 0.023626994341611862\n",
      "377 0.025683073326945305\n",
      "378 0.023310648277401924\n",
      "379 0.022864894941449165\n",
      "380 0.023592103272676468\n",
      "381 0.024177882820367813\n",
      "done\n",
      "5.611293990595001e-05\n",
      "0.02369881408162298\n",
      "0.007037690401818428\n",
      "0.9770842129023287\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.611293990595001e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.611293990595001e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
