{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_W4L import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 13 21:47:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.04    Driver Version: 455.23.04    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "|  0%   51C    P8    34W / 370W |   1441MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:68:00.0 Off |                  N/A |\n",
      "| 30%   40C    P0    70W / 350W |      0MiB / 24265MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     18512      C   ...conda3/envs/ai/bin/python     1439MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'save/model_W4L'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_15000  save_35000  save_50000  save_65000  save_85000\r\n",
      "save_0\t     save_20000  save_40000  save_55000  save_70000  save_90000\r\n",
      "save_10000   save_25000  save_45000  save_58396  save_75000  save_95000\r\n",
      "save_100000  save_30000  save_5000   save_60000  save_80000\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 124.1MiB\n",
      "TTS size 36.5MiB\n",
      "MelDecoder size 22.9MiB\n",
      "loaded : 100000\n",
      "100000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 100000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f04183d3c90>\n"
     ]
    }
   ],
   "source": [
    "testset = LJDataset(tts_hparams, split='test')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05117952823638916\n",
      "1 0.05328477919101715\n",
      "2 0.050713758915662766\n",
      "3 0.05012204498052597\n",
      "4 0.05137081444263458\n",
      "5 0.048514194786548615\n",
      "6 0.048756733536720276\n",
      "7 0.04893988370895386\n",
      "8 0.04954352602362633\n",
      "9 0.04991484433412552\n",
      "10 0.049470651894807816\n",
      "11 0.046213723719120026\n",
      "12 0.04611681401729584\n",
      "13 0.05175754055380821\n",
      "14 0.04774719849228859\n",
      "15 0.05252053588628769\n",
      "16 0.05569665879011154\n",
      "17 0.04767701029777527\n",
      "18 0.053088244050741196\n",
      "19 0.04904475808143616\n",
      "20 0.05004804953932762\n",
      "21 0.0522751621901989\n",
      "22 0.04533199593424797\n",
      "23 0.05048172548413277\n",
      "24 0.04923214390873909\n",
      "25 0.04895111173391342\n",
      "26 0.04730668663978577\n",
      "27 0.04635137319564819\n",
      "28 0.052181679755449295\n",
      "29 0.04959711804986\n",
      "30 0.04889385402202606\n",
      "31 0.048393238335847855\n",
      "32 0.04846106469631195\n",
      "33 0.045911602675914764\n",
      "34 0.05393170565366745\n",
      "35 0.05001062527298927\n",
      "36 0.050474829971790314\n",
      "37 0.0512676015496254\n",
      "38 0.04823332279920578\n",
      "39 0.0471385233104229\n",
      "40 0.048709459602832794\n",
      "41 0.04884311929345131\n",
      "42 0.05511021614074707\n",
      "43 0.05468567833304405\n",
      "44 0.05101048946380615\n",
      "45 0.04644624888896942\n",
      "46 0.047607872635126114\n",
      "47 0.04707583039999008\n",
      "48 0.04985147342085838\n",
      "49 0.041520338505506516\n",
      "50 0.046502549201250076\n",
      "51 0.046956826001405716\n",
      "52 0.0484071783721447\n",
      "53 0.04973459988832474\n",
      "54 0.05258003994822502\n",
      "55 0.04661843553185463\n",
      "56 0.046797316521406174\n",
      "57 0.056509144604206085\n",
      "58 0.0467098094522953\n",
      "59 0.04962771385908127\n",
      "60 0.04596399515867233\n",
      "61 0.048144981265068054\n",
      "62 0.04845298454165459\n",
      "63 0.048935968428850174\n",
      "64 0.045984260737895966\n",
      "65 0.051087550818920135\n",
      "66 0.044352512806653976\n",
      "67 0.04814216494560242\n",
      "68 0.04906640574336052\n",
      "69 0.04769529402256012\n",
      "70 0.04997647553682327\n",
      "71 0.04853460192680359\n",
      "72 0.04763241857290268\n",
      "73 0.05038335546851158\n",
      "74 0.044298071414232254\n",
      "75 0.04888053238391876\n",
      "76 0.049772970378398895\n",
      "77 0.048326343297958374\n",
      "78 0.04537106305360794\n",
      "79 0.04347006231546402\n",
      "80 0.04992415010929108\n",
      "81 0.047612372785806656\n",
      "82 0.048092540353536606\n",
      "83 0.047033775597810745\n",
      "84 0.04639650136232376\n",
      "85 0.04762839525938034\n",
      "86 0.04642680659890175\n",
      "87 0.048225924372673035\n",
      "88 0.045867618173360825\n",
      "89 0.04669509083032608\n",
      "90 0.048681411892175674\n",
      "91 0.05173248052597046\n",
      "92 0.048579052090644836\n",
      "93 0.049614205956459045\n",
      "94 0.04617604613304138\n",
      "95 0.048536933958530426\n",
      "96 0.04856026917695999\n",
      "97 0.04905217885971069\n",
      "98 0.04472546651959419\n",
      "99 0.04531657323241234\n",
      "100 0.046688809990882874\n",
      "101 0.04467179626226425\n",
      "102 0.04667922481894493\n",
      "103 0.046365175396203995\n",
      "104 0.046001069247722626\n",
      "105 0.0458376370370388\n",
      "106 0.04734835773706436\n",
      "107 0.04669985547661781\n",
      "108 0.05141797661781311\n",
      "109 0.04520867392420769\n",
      "110 0.044907346367836\n",
      "111 0.04642197862267494\n",
      "112 0.04597596451640129\n",
      "113 0.04622891917824745\n",
      "114 0.045191191136837006\n",
      "115 0.045429546386003494\n",
      "116 0.04489704594016075\n",
      "117 0.046430665999650955\n",
      "118 0.04488324373960495\n",
      "119 0.04637633264064789\n",
      "120 0.04526326432824135\n",
      "121 0.04484757035970688\n",
      "122 0.05064323917031288\n",
      "123 0.04780980944633484\n",
      "124 0.04520205035805702\n",
      "125 0.0455932579934597\n",
      "126 0.04537228122353554\n",
      "127 0.04361794516444206\n",
      "128 0.04127892106771469\n",
      "129 0.04265403002500534\n",
      "130 0.04538837820291519\n",
      "131 0.04546419158577919\n",
      "132 0.04628761485219002\n",
      "133 0.047851867973804474\n",
      "134 0.048024337738752365\n",
      "135 0.04291345551609993\n",
      "136 0.04536687210202217\n",
      "137 0.0472254678606987\n",
      "138 0.04445064440369606\n",
      "139 0.04357968270778656\n",
      "140 0.05082239955663681\n",
      "141 0.051917627453804016\n",
      "142 0.05080467835068703\n",
      "143 0.04821164160966873\n",
      "144 0.04891210421919823\n",
      "145 0.04715513065457344\n",
      "146 0.046403829008340836\n",
      "147 0.04570925980806351\n",
      "148 0.0453251414000988\n",
      "149 0.0461340956389904\n",
      "150 0.0475294254720211\n",
      "151 0.04735832288861275\n",
      "152 0.0454631969332695\n",
      "153 0.045931749045848846\n",
      "154 0.0465838760137558\n",
      "155 0.04458581656217575\n",
      "156 0.042797911912202835\n",
      "157 0.045122139155864716\n",
      "158 0.044562339782714844\n",
      "159 0.04412213712930679\n",
      "160 0.04356971010565758\n",
      "161 0.043313827365636826\n",
      "162 0.04341934621334076\n",
      "163 0.04574710875749588\n",
      "164 0.04514042288064957\n",
      "165 0.04669738560914993\n",
      "166 0.04445968568325043\n",
      "167 0.048309653997421265\n",
      "168 0.046813029795885086\n",
      "169 0.045018021017313004\n",
      "170 0.045430876314640045\n",
      "171 0.04440123960375786\n",
      "172 0.04496260732412338\n",
      "173 0.04092561826109886\n",
      "174 0.04725366085767746\n",
      "175 0.0447121188044548\n",
      "176 0.04612329602241516\n",
      "177 0.04680011048913002\n",
      "178 0.04508376866579056\n",
      "179 0.04706593230366707\n",
      "180 0.0465005524456501\n",
      "181 0.04523734748363495\n",
      "182 0.04737938940525055\n",
      "183 0.04535510390996933\n",
      "184 0.04253639653325081\n",
      "185 0.04356444254517555\n",
      "186 0.044553063809871674\n",
      "187 0.045142509043216705\n",
      "188 0.04244127497076988\n",
      "189 0.04820249602198601\n",
      "190 0.04701286554336548\n",
      "191 0.046126123517751694\n",
      "192 0.04729605093598366\n",
      "193 0.04317721351981163\n",
      "194 0.04475709795951843\n",
      "195 0.04423944652080536\n",
      "196 0.0473008006811142\n",
      "197 0.044531699270009995\n",
      "198 0.04379425197839737\n",
      "199 0.0427083894610405\n",
      "200 0.042112354189157486\n",
      "201 0.042435843497514725\n",
      "202 0.042337678372859955\n",
      "203 0.04106968641281128\n",
      "204 0.046943578869104385\n",
      "205 0.04633088782429695\n",
      "206 0.04939446225762367\n",
      "207 0.04717520624399185\n",
      "208 0.04670356959104538\n",
      "209 0.04271112382411957\n",
      "210 0.04714253917336464\n",
      "211 0.045843638479709625\n",
      "212 0.045815858989953995\n",
      "213 0.04273447021842003\n",
      "214 0.04360653832554817\n",
      "215 0.04378259927034378\n",
      "216 0.044459372758865356\n",
      "217 0.046079687774181366\n",
      "218 0.04671434685587883\n",
      "219 0.0436532087624073\n",
      "220 0.04710785299539566\n",
      "221 0.0424196757376194\n",
      "222 0.04094763472676277\n",
      "223 0.041412774473428726\n",
      "224 0.04804258421063423\n",
      "225 0.04548397660255432\n",
      "226 0.04670252278447151\n",
      "227 0.04392025247216225\n",
      "228 0.04360676184296608\n",
      "229 0.04723774269223213\n",
      "230 0.04478560388088226\n",
      "231 0.045602843165397644\n",
      "232 0.04313689097762108\n",
      "233 0.044391948729753494\n",
      "234 0.04348529502749443\n",
      "235 0.045988693833351135\n",
      "236 0.04506722837686539\n",
      "237 0.04255634546279907\n",
      "238 0.045863378793001175\n",
      "239 0.044975169003009796\n",
      "240 0.046400945633649826\n",
      "241 0.04818682000041008\n",
      "242 0.04447956010699272\n",
      "243 0.046702124178409576\n",
      "244 0.04453887790441513\n",
      "245 0.04587080702185631\n",
      "246 0.046353086829185486\n",
      "247 0.04313749819993973\n",
      "248 0.04202350974082947\n",
      "249 0.044901467859745026\n",
      "250 0.04442629590630531\n",
      "251 0.038741983473300934\n",
      "252 0.0486210472881794\n",
      "253 0.043698377907276154\n",
      "254 0.04565750062465668\n",
      "255 0.04401450604200363\n",
      "256 0.04521191865205765\n",
      "257 0.04626816138625145\n",
      "258 0.045376766473054886\n",
      "259 0.04447746276855469\n",
      "260 0.047736722975969315\n",
      "261 0.042779333889484406\n",
      "262 0.04605209827423096\n",
      "263 0.048507481813430786\n",
      "264 0.047924622893333435\n",
      "265 0.04402761906385422\n",
      "266 0.050215017050504684\n",
      "267 0.047166526317596436\n",
      "268 0.04444094002246857\n",
      "269 0.044313330203294754\n",
      "270 0.046048443764448166\n",
      "271 0.046308733522892\n",
      "272 0.047901954501867294\n",
      "273 0.044818803668022156\n",
      "274 0.0429241843521595\n",
      "275 0.046298880130052567\n",
      "276 0.04444175586104393\n",
      "277 0.04653603583574295\n",
      "278 0.04570464789867401\n",
      "279 0.042992640286684036\n",
      "280 0.04232868552207947\n",
      "281 0.042517147958278656\n",
      "282 0.044602081179618835\n",
      "283 0.04680337384343147\n",
      "284 0.04524693265557289\n",
      "285 0.04490618407726288\n",
      "286 0.046140406280756\n",
      "287 0.04543999582529068\n",
      "288 0.04561811313033104\n",
      "289 0.04403558745980263\n",
      "290 0.04439045861363411\n",
      "291 0.0464337095618248\n",
      "292 0.046466171741485596\n",
      "293 0.04581752419471741\n",
      "294 0.04669170454144478\n",
      "295 0.04200781509280205\n",
      "296 0.04594740271568298\n",
      "297 0.044295426458120346\n",
      "298 0.043638676404953\n",
      "299 0.044720832258462906\n",
      "300 0.04236402362585068\n",
      "301 0.04592595621943474\n",
      "302 0.044552017003297806\n",
      "303 0.048909127712249756\n",
      "304 0.04315250366926193\n",
      "305 0.04143725335597992\n",
      "306 0.044487860053777695\n",
      "307 0.04352301359176636\n",
      "308 0.04614165797829628\n",
      "309 0.04867931082844734\n",
      "310 0.04228755086660385\n",
      "311 0.044284142553806305\n",
      "312 0.04471088573336601\n",
      "313 0.044473931193351746\n",
      "314 0.04569489136338234\n",
      "315 0.042505282908678055\n",
      "316 0.042062439024448395\n",
      "317 0.044875193387269974\n",
      "318 0.043513257056474686\n",
      "319 0.04380730539560318\n",
      "320 0.043629035353660583\n",
      "321 0.0434345006942749\n",
      "322 0.04938211664557457\n",
      "323 0.045027777552604675\n",
      "324 0.04563107714056969\n",
      "325 0.04814963787794113\n",
      "326 0.045253437012434006\n",
      "327 0.043088752776384354\n",
      "328 0.04448758065700531\n",
      "329 0.04421943798661232\n",
      "330 0.043845269829034805\n",
      "331 0.047506000846624374\n",
      "332 0.0453832782804966\n",
      "333 0.04453331604599953\n",
      "334 0.042606305330991745\n",
      "335 0.043722715228796005\n",
      "336 0.04290857911109924\n",
      "337 0.047952163964509964\n",
      "338 0.044906098395586014\n",
      "339 0.04365630820393562\n",
      "340 0.0438326895236969\n",
      "341 0.04371901974081993\n",
      "342 0.04503873735666275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 0.0408361442387104\n",
      "344 0.04355400428175926\n",
      "345 0.04189413785934448\n",
      "346 0.0417381227016449\n",
      "347 0.04582593962550163\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11727559972173472\n",
      "0.046232935608546626\n",
      "0.014900211046781691\n",
      "0.2766318055319375\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
