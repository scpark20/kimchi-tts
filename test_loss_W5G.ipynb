{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_W5G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 19 12:56:01 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:2E:00.0 Off |                  N/A |\r\n",
      "| 54%   62C    P2   103W / 250W |   1678MiB / 11016MiB |     30%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |\r\n",
      "| 56%   66C    P2   184W / 250W |   3645MiB / 11019MiB |     88%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     15546      C   ...onda3/envs/vae/bin/python     1675MiB |\r\n",
      "|    1   N/A  N/A     15524      C   ...onda3/envs/vae/bin/python     1843MiB |\r\n",
      "|    1   N/A  N/A     15526      C   ...onda3/envs/vae/bin/python     1799MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/model_W5G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_140000  save_20000   save_250000  save_312251  save_45000\r\n",
      "save_100000  save_145000  save_200000  save_255000  save_315000  save_50000\r\n",
      "save_100003  save_15000   save_205000  save_260000  save_320000  save_55000\r\n",
      "save_105000  save_150000  save_207498  save_265000  save_320618  save_60000\r\n",
      "save_108400  save_155000  save_20951   save_270000  save_325000  save_65000\r\n",
      "save_110000  save_160000  save_210000  save_275000  save_330000  save_67743\r\n",
      "save_112252  save_165000  save_213814  save_275660  save_330312  save_70000\r\n",
      "save_112360  save_165513  save_215000  save_280000  save_335000  save_75000\r\n",
      "save_113679  save_169764  save_220000  save_285000  save_340000  save_77732\r\n",
      "save_115000  save_170000  save_224267  save_290000  save_345000  save_80000\r\n",
      "save_120000  save_175000  save_225000  save_293000  save_348351  save_85000\r\n",
      "save_125000  save_180000  save_230000  save_295000  save_35000\t save_85982\r\n",
      "save_130000  save_185000  save_235000  save_30000   save_38005\t save_90000\r\n",
      "save_131258  save_190000  save_240000  save_300000  save_40000\t save_95000\r\n",
      "save_135000  save_195000  save_245000  save_305000  save_400000  save_96773\r\n",
      "save_138640  save_196255  save_25000   save_310000  save_42922\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 132.9MiB\n",
      "TTS size 45.2MiB\n",
      "MelDecoder size 28.7MiB\n",
      "loaded : 400000\n",
      "400000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 400000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6730f1cee0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f672d4d6d30>\n"
     ]
    }
   ],
   "source": [
    "trainset = LJDataset(tts_hparams, split='train')\n",
    "testset = LJDataset(tts_hparams, split='valid')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, num_workers=1, #tts_hparams.num_workers, \n",
    "                          shuffle=True, sampler=None, batch_size=tts_hparams.batch_size, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(train_loader)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.02426605112850666\n",
      "1 0.022838551551103592\n",
      "2 0.02337535470724106\n",
      "3 0.025763504207134247\n",
      "4 0.027001088485121727\n",
      "5 0.024851160123944283\n",
      "6 0.02446964755654335\n",
      "7 0.024855243042111397\n",
      "8 0.02707437239587307\n",
      "9 0.024453584104776382\n",
      "10 0.02621963806450367\n",
      "11 0.02769777551293373\n",
      "12 0.026133226230740547\n",
      "13 0.027506912127137184\n",
      "14 0.02485697716474533\n",
      "15 0.02594061754643917\n",
      "16 0.02725783735513687\n",
      "17 0.027164652943611145\n",
      "18 0.02730446495115757\n",
      "19 0.026360634714365005\n",
      "20 0.026033712550997734\n",
      "21 0.026163220405578613\n",
      "22 0.024749964475631714\n",
      "23 0.026501616463065147\n",
      "24 0.027214596047997475\n",
      "25 0.026498988270759583\n",
      "26 0.0263333972543478\n",
      "27 0.02510468102991581\n",
      "28 0.026536645367741585\n",
      "29 0.026459338143467903\n",
      "30 0.025635959580540657\n",
      "31 0.02333526685833931\n",
      "32 0.022524336352944374\n",
      "33 0.02690778858959675\n",
      "34 0.027661962434649467\n",
      "35 0.025010909885168076\n",
      "36 0.02521771937608719\n",
      "37 0.02509400062263012\n",
      "38 0.024197649210691452\n",
      "39 0.025675790384411812\n",
      "40 0.02577301487326622\n",
      "41 0.026644811034202576\n",
      "42 0.024513034150004387\n",
      "43 0.025134127587080002\n",
      "44 0.02734113298356533\n",
      "45 0.028180012479424477\n",
      "46 0.02627761848270893\n",
      "47 0.02319115400314331\n",
      "48 0.0277334526181221\n",
      "49 0.025294989347457886\n",
      "50 0.023399638012051582\n",
      "51 0.02264653705060482\n",
      "52 0.02512114867568016\n",
      "53 0.025973577052354813\n",
      "54 0.024860981851816177\n",
      "55 0.024366313591599464\n",
      "56 0.0236845500767231\n",
      "57 0.02727167122066021\n",
      "58 0.027764542028307915\n",
      "59 0.025377653539180756\n",
      "60 0.0248859953135252\n",
      "61 0.02712886407971382\n",
      "62 0.028134427964687347\n",
      "63 0.024632606655359268\n",
      "64 0.02659630961716175\n",
      "65 0.023881828412413597\n",
      "66 0.029507730156183243\n",
      "67 0.025245826691389084\n",
      "68 0.026140613481402397\n",
      "69 0.025640692561864853\n",
      "70 0.025734780356287956\n",
      "71 0.02839755080640316\n",
      "72 0.026758043095469475\n",
      "73 0.02618829719722271\n",
      "74 0.025306295603513718\n",
      "75 0.026334499940276146\n",
      "76 0.024600528180599213\n",
      "77 0.02609909512102604\n",
      "78 0.027861636132001877\n",
      "79 0.028777217492461205\n",
      "80 0.028314733877778053\n",
      "81 0.02716006711125374\n",
      "82 0.024870233610272408\n",
      "83 0.02820502780377865\n",
      "84 0.02632669173181057\n",
      "85 0.025797462090849876\n",
      "86 0.028618764132261276\n",
      "87 0.023536667227745056\n",
      "88 0.026045629754662514\n",
      "89 0.023681923747062683\n",
      "90 0.02712143398821354\n",
      "91 0.027387991547584534\n",
      "92 0.025627246126532555\n",
      "93 0.026285365223884583\n",
      "94 0.02651548571884632\n",
      "95 0.026134973391890526\n",
      "96 0.027386244386434555\n",
      "97 0.02434760332107544\n",
      "98 0.025429215282201767\n",
      "99 0.024950800463557243\n",
      "100 0.02498440071940422\n",
      "101 0.025719517841935158\n",
      "102 0.0277349092066288\n",
      "103 0.027618270367383957\n",
      "104 0.025633947923779488\n",
      "105 0.02482863888144493\n",
      "106 0.027542075142264366\n",
      "107 0.024849241599440575\n",
      "108 0.025217602029442787\n",
      "109 0.02499503269791603\n",
      "110 0.024948321282863617\n",
      "111 0.02626093663275242\n",
      "112 0.02597227320075035\n",
      "113 0.02653741091489792\n",
      "114 0.026459448039531708\n",
      "115 0.025084715336561203\n",
      "116 0.025681009516119957\n",
      "117 0.025644371286034584\n",
      "118 0.02758610062301159\n",
      "119 0.02722032554447651\n",
      "120 0.027917155995965004\n",
      "121 0.025715503841638565\n",
      "122 0.026383599266409874\n",
      "123 0.027663525193929672\n",
      "124 0.02864525280892849\n",
      "125 0.02398597076535225\n",
      "126 0.02462359331548214\n",
      "127 0.02599060721695423\n",
      "128 0.024594999849796295\n",
      "129 0.02385442517697811\n",
      "130 0.0253156665712595\n",
      "131 0.02532288432121277\n",
      "132 0.02954518236219883\n",
      "133 0.02756950818002224\n",
      "134 0.02525990456342697\n",
      "135 0.02676992677152157\n",
      "136 0.028079502284526825\n",
      "137 0.027364391833543777\n",
      "138 0.026939664036035538\n",
      "139 0.026984121650457382\n",
      "140 0.024179186671972275\n",
      "141 0.02569303661584854\n",
      "142 0.02563326619565487\n",
      "143 0.025673476979136467\n",
      "144 0.025972288101911545\n",
      "145 0.0245534498244524\n",
      "146 0.027646254748106003\n",
      "147 0.0261473897844553\n",
      "148 0.02374967187643051\n",
      "149 0.02792431227862835\n",
      "150 0.02256414294242859\n",
      "151 0.025380272418260574\n",
      "152 0.02669042907655239\n",
      "153 0.025380749255418777\n",
      "154 0.026432961225509644\n",
      "155 0.02456704154610634\n",
      "156 0.024596303701400757\n",
      "157 0.026553088799118996\n",
      "158 0.02439568005502224\n",
      "159 0.026267006993293762\n",
      "160 0.026734493672847748\n",
      "161 0.02522648684680462\n",
      "162 0.02635038085281849\n",
      "163 0.022564833983778954\n",
      "164 0.02535754069685936\n",
      "165 0.025510555133223534\n",
      "166 0.023985715582966805\n",
      "167 0.025887228548526764\n",
      "168 0.024492688477039337\n",
      "169 0.026555798947811127\n",
      "170 0.025494469329714775\n",
      "171 0.0246196947991848\n",
      "172 0.026195485144853592\n",
      "173 0.026486672461032867\n",
      "174 0.027077578008174896\n",
      "175 0.02631407044827938\n",
      "176 0.027964605018496513\n",
      "177 0.024187786504626274\n",
      "178 0.025892158970236778\n",
      "179 0.026328930631279945\n",
      "180 0.026280850172042847\n",
      "181 0.022533027455210686\n",
      "182 0.02584073878824711\n",
      "183 0.025948984548449516\n",
      "184 0.02434311993420124\n",
      "185 0.025313306599855423\n",
      "186 0.025937538594007492\n",
      "187 0.026306670159101486\n",
      "188 0.025672581046819687\n",
      "189 0.026238368824124336\n",
      "190 0.02661004848778248\n",
      "191 0.025254370644688606\n",
      "192 0.025773121044039726\n",
      "193 0.024082830175757408\n",
      "194 0.027394268661737442\n",
      "195 0.024761222302913666\n",
      "196 0.026151692494750023\n",
      "197 0.02482730522751808\n",
      "198 0.025959718972444534\n",
      "199 0.028384650126099586\n",
      "200 0.027178071439266205\n",
      "201 0.025594258680939674\n",
      "202 0.02707936428487301\n",
      "203 0.02818240225315094\n",
      "204 0.028567437082529068\n",
      "205 0.02522057667374611\n",
      "206 0.025378769263625145\n",
      "207 0.023714344948530197\n",
      "208 0.024562301114201546\n",
      "209 0.02406752109527588\n",
      "210 0.027877328917384148\n",
      "211 0.025475937873125076\n",
      "212 0.025236504152417183\n",
      "213 0.026208743453025818\n",
      "214 0.025936108082532883\n",
      "215 0.028200291097164154\n",
      "216 0.025025632232427597\n",
      "217 0.026145178824663162\n",
      "218 0.022546973079442978\n",
      "219 0.028387844562530518\n",
      "220 0.02413461171090603\n",
      "221 0.024677371606230736\n",
      "222 0.02818109840154648\n",
      "223 0.02455557882785797\n",
      "224 0.026803620159626007\n",
      "225 0.02622971683740616\n",
      "226 0.026977678760886192\n",
      "227 0.026767734438180923\n",
      "228 0.02688506431877613\n",
      "229 0.024189231917262077\n",
      "230 0.024874376133084297\n",
      "231 0.024695061147212982\n",
      "232 0.02430720627307892\n",
      "233 0.024963481351733208\n",
      "234 0.026615656912326813\n",
      "235 0.024575944989919662\n",
      "236 0.027775872498750687\n",
      "237 0.026125334203243256\n",
      "238 0.0261138416826725\n",
      "239 0.024183860048651695\n",
      "240 0.02722129411995411\n",
      "241 0.027414344251155853\n",
      "242 0.026146726682782173\n",
      "243 0.02585368975996971\n",
      "244 0.02532663568854332\n",
      "245 0.025880374014377594\n",
      "246 0.026805348694324493\n",
      "247 0.024115242063999176\n",
      "248 0.028011629357933998\n",
      "249 0.02497567981481552\n",
      "250 0.025392651557922363\n",
      "251 0.02488439716398716\n",
      "252 0.024218657985329628\n",
      "253 0.028525743633508682\n",
      "254 0.022157348692417145\n",
      "255 0.023241935297846794\n",
      "256 0.024658899754285812\n",
      "257 0.02451356314122677\n",
      "258 0.02362312376499176\n",
      "259 0.02258218079805374\n",
      "260 0.02480669692158699\n",
      "261 0.027637122198939323\n",
      "262 0.025943230837583542\n",
      "263 0.02682151272892952\n",
      "264 0.02504279837012291\n",
      "265 0.02441590651869774\n",
      "266 0.023864444345235825\n",
      "267 0.027083443477749825\n",
      "268 0.028159210458397865\n",
      "269 0.029907656833529472\n",
      "270 0.025240788236260414\n",
      "271 0.02788989432156086\n",
      "272 0.02833508513867855\n",
      "273 0.024490702897310257\n",
      "274 0.025798283517360687\n",
      "275 0.024472549557685852\n",
      "276 0.02630758471786976\n",
      "277 0.028885915875434875\n",
      "278 0.025331221520900726\n",
      "279 0.02768360637128353\n",
      "280 0.02450445666909218\n",
      "281 0.027915114536881447\n",
      "282 0.027687031775712967\n",
      "283 0.025482062250375748\n",
      "284 0.025582708418369293\n",
      "285 0.024891795590519905\n",
      "286 0.02570304274559021\n",
      "287 0.02744239568710327\n",
      "288 0.02693908102810383\n",
      "289 0.026810945942997932\n",
      "290 0.02461399883031845\n",
      "291 0.026213858276605606\n",
      "292 0.02757224813103676\n",
      "293 0.025233270600438118\n",
      "294 0.024393057450652122\n",
      "295 0.026341058313846588\n",
      "296 0.02628924511373043\n",
      "297 0.02464454434812069\n",
      "298 0.024865133687853813\n",
      "299 0.023777877911925316\n",
      "300 0.026006203144788742\n",
      "301 0.025215499103069305\n",
      "302 0.0259251669049263\n",
      "303 0.025260135531425476\n",
      "304 0.02635016106069088\n",
      "305 0.025435684248805046\n",
      "306 0.02471316047012806\n",
      "307 0.02560877613723278\n",
      "308 0.027214523404836655\n",
      "309 0.02747778594493866\n",
      "310 0.025665998458862305\n",
      "311 0.026149539276957512\n",
      "312 0.02599831484258175\n",
      "313 0.024150673300027847\n",
      "314 0.023693501949310303\n",
      "315 0.02641620673239231\n",
      "316 0.027703937143087387\n",
      "317 0.027590110898017883\n",
      "318 0.02744237147271633\n",
      "319 0.026550045236945152\n",
      "320 0.023799147456884384\n",
      "321 0.02620396763086319\n",
      "322 0.023498686030507088\n",
      "323 0.02020649053156376\n",
      "324 0.026112763211131096\n",
      "325 0.024395983666181564\n",
      "326 0.024803007021546364\n",
      "327 0.02194399945437908\n",
      "328 0.02580554224550724\n",
      "329 0.02684668079018593\n",
      "330 0.02587239071726799\n",
      "331 0.026514999568462372\n",
      "332 0.025970665737986565\n",
      "333 0.02532181330025196\n",
      "334 0.025164520367980003\n",
      "335 0.027358999475836754\n",
      "336 0.025345386937260628\n",
      "337 0.026561250910162926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 0.026502545922994614\n",
      "339 0.027018845081329346\n",
      "340 0.028190163895487785\n",
      "341 0.025733202695846558\n",
      "342 0.02662874013185501\n",
      "343 0.02658284455537796\n",
      "344 0.02667674608528614\n",
      "345 0.02469494193792343\n",
      "346 0.027871057391166687\n",
      "347 0.025258779525756836\n",
      "348 0.025096306577324867\n",
      "349 0.02541038766503334\n",
      "350 0.027150887995958328\n",
      "351 0.024090472608804703\n",
      "352 0.02454935386776924\n",
      "353 0.025550242513418198\n",
      "354 0.02747110091149807\n",
      "355 0.0257249902933836\n",
      "356 0.026379013434052467\n",
      "357 0.027974244207143784\n",
      "358 0.02880275249481201\n",
      "359 0.023139843717217445\n",
      "360 0.025396475568413734\n",
      "361 0.02504163235425949\n",
      "362 0.027628596872091293\n",
      "363 0.028561430051922798\n",
      "364 0.025943424552679062\n",
      "365 0.023778000846505165\n",
      "366 0.024771038442850113\n",
      "367 0.026474859565496445\n",
      "368 0.028862327337265015\n",
      "369 0.024619750678539276\n",
      "370 0.026295192539691925\n",
      "371 0.026579245924949646\n",
      "372 0.025796834379434586\n",
      "373 0.027061140164732933\n",
      "374 0.025946825742721558\n",
      "375 0.024021003395318985\n",
      "376 0.02628871612250805\n",
      "377 0.025415925309062004\n",
      "378 0.027078095823526382\n",
      "379 0.02462504245340824\n",
      "380 0.02360052801668644\n",
      "381 0.025414329022169113\n",
      "done\n",
      "0.0004585173167360682\n",
      "0.025861415387916316\n",
      "0.008793667652424796\n",
      "1.0493611173792035\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
