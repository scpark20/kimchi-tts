{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_W5G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 15 17:19:14 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:2E:00.0 Off |                  N/A |\n",
      "| 54%   61C    P0    74W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |\n",
      "| 52%   54C    P8    29W / 250W |   1846MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     18102      C   ...onda3/envs/vae/bin/python     1843MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/model_W5G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_120000  save_155000  save_195000  save_38005\tsave_75000\r\n",
      "save_100000  save_125000  save_160000  save_196255  save_40000\tsave_77732\r\n",
      "save_100003  save_130000  save_165000  save_20000   save_42922\tsave_80000\r\n",
      "save_105000  save_131258  save_165513  save_200000  save_45000\tsave_85000\r\n",
      "save_108400  save_135000  save_169764  save_205000  save_50000\tsave_85982\r\n",
      "save_110000  save_138640  save_170000  save_207498  save_55000\tsave_90000\r\n",
      "save_112252  save_140000  save_175000  save_20951   save_60000\tsave_95000\r\n",
      "save_112360  save_145000  save_180000  save_25000   save_65000\tsave_96773\r\n",
      "save_113679  save_15000   save_185000  save_30000   save_67743\r\n",
      "save_115000  save_150000  save_190000  save_35000   save_70000\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 132.9MiB\n",
      "TTS size 45.2MiB\n",
      "MelDecoder size 28.7MiB\n",
      "loaded : 200000\n",
      "200000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 200000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff1d0913190>\n"
     ]
    }
   ],
   "source": [
    "testset = LJDataset(tts_hparams, split='valid')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04715722054243088\n",
      "1 0.04360160604119301\n",
      "2 0.04405490309000015\n",
      "3 0.04687179997563362\n",
      "4 0.04639536887407303\n",
      "5 0.04458916187286377\n",
      "6 0.0459538996219635\n",
      "7 0.04425394535064697\n",
      "8 0.04579484835267067\n",
      "9 0.04171115159988403\n",
      "10 0.044945962727069855\n",
      "11 0.04520116746425629\n",
      "12 0.043805088847875595\n",
      "13 0.043837498873472214\n",
      "14 0.044868044555187225\n",
      "15 0.04634243622422218\n",
      "16 0.048601824790239334\n",
      "17 0.04515663534402847\n",
      "18 0.04852774366736412\n",
      "19 0.04520774260163307\n",
      "20 0.04550336301326752\n",
      "21 0.044040337204933167\n",
      "22 0.04459396004676819\n",
      "23 0.04510466009378433\n",
      "24 0.0460255965590477\n",
      "25 0.04939733445644379\n",
      "26 0.04588458687067032\n",
      "27 0.04361061006784439\n",
      "28 0.04475771635770798\n",
      "29 0.04610371217131615\n",
      "30 0.04492596164345741\n",
      "31 0.04231884330511093\n",
      "32 0.04899398237466812\n",
      "33 0.04238775745034218\n",
      "34 0.04774579033255577\n",
      "35 0.043092645704746246\n",
      "36 0.043703820556402206\n",
      "37 0.04540408402681351\n",
      "38 0.04505961015820503\n",
      "39 0.046187520027160645\n",
      "40 0.04666530340909958\n",
      "41 0.04288794845342636\n",
      "42 0.04285387322306633\n",
      "43 0.041312310844659805\n",
      "44 0.03553449362516403\n",
      "45 0.04373747482895851\n",
      "46 0.04625706374645233\n",
      "47 0.04155929014086723\n",
      "48 0.04096975177526474\n",
      "49 0.041981663554906845\n",
      "50 0.041050393134355545\n",
      "51 0.04828331619501114\n",
      "52 0.04395857825875282\n",
      "53 0.043371718376874924\n",
      "54 0.05049275979399681\n",
      "55 0.04514199495315552\n",
      "56 0.04512191191315651\n",
      "57 0.04255584627389908\n",
      "58 0.04183483123779297\n",
      "59 0.04938830807805061\n",
      "60 0.044428858906030655\n",
      "61 0.04229271784424782\n",
      "62 0.04261213168501854\n",
      "63 0.04661436751484871\n",
      "64 0.0421656109392643\n",
      "65 0.04215708747506142\n",
      "66 0.04372672364115715\n",
      "67 0.04414641112089157\n",
      "68 0.042094990611076355\n",
      "69 0.044545501470565796\n",
      "70 0.04645596072077751\n",
      "71 0.043486203998327255\n",
      "72 0.04225930571556091\n",
      "73 0.04533589631319046\n",
      "74 0.04920772835612297\n",
      "75 0.039831001311540604\n",
      "76 0.0422026701271534\n",
      "77 0.042097073048353195\n",
      "78 0.04385331645607948\n",
      "79 0.04467245191335678\n",
      "80 0.04361039772629738\n",
      "81 0.04207926616072655\n",
      "82 0.04261618107557297\n",
      "83 0.04419863596558571\n",
      "84 0.046251971274614334\n",
      "85 0.04583623260259628\n",
      "86 0.04375859722495079\n",
      "87 0.041457995772361755\n",
      "88 0.04377447068691254\n",
      "89 0.044421032071113586\n",
      "90 0.04434838891029358\n",
      "91 0.04615671560168266\n",
      "92 0.04205912724137306\n",
      "93 0.045689791440963745\n",
      "94 0.040005724877119064\n",
      "95 0.04175639525055885\n",
      "96 0.04343988373875618\n",
      "97 0.044002629816532135\n",
      "98 0.043600089848041534\n",
      "99 0.04377276450395584\n",
      "100 0.04489826038479805\n",
      "101 0.04128023609519005\n",
      "102 0.04360809922218323\n",
      "103 0.04098113998770714\n",
      "104 0.042709365487098694\n",
      "105 0.041488148272037506\n",
      "106 0.04557562246918678\n",
      "107 0.04224507883191109\n",
      "108 0.04324156790971756\n",
      "109 0.04209451749920845\n",
      "110 0.04309728741645813\n",
      "111 0.04334218055009842\n",
      "112 0.04272445663809776\n",
      "113 0.046533457934856415\n",
      "114 0.04389561340212822\n",
      "115 0.042470913380384445\n",
      "116 0.04454529657959938\n",
      "117 0.04325379431247711\n",
      "118 0.042657919228076935\n",
      "119 0.04239426925778389\n",
      "120 0.04515177384018898\n",
      "121 0.04126237705349922\n",
      "122 0.04551475867629051\n",
      "123 0.045431848615407944\n",
      "124 0.04097678139805794\n",
      "125 0.0424976721405983\n",
      "126 0.04237842187285423\n",
      "127 0.04553394764661789\n",
      "128 0.040371499955654144\n",
      "129 0.042532093822956085\n",
      "130 0.04492823779582977\n",
      "131 0.0449499674141407\n",
      "132 0.05395440384745598\n",
      "133 0.053862567991018295\n",
      "134 0.05459342524409294\n",
      "135 0.05432042106986046\n",
      "136 0.04662444069981575\n",
      "137 0.05359655246138573\n",
      "138 0.05346473306417465\n",
      "139 0.04791268706321716\n",
      "140 0.04813650995492935\n",
      "141 0.052669551223516464\n",
      "142 0.04645967110991478\n",
      "143 0.048417072743177414\n",
      "144 0.04539860412478447\n",
      "145 0.04882212355732918\n",
      "146 0.044546086341142654\n",
      "147 0.050353292375802994\n",
      "148 0.048684488981962204\n",
      "149 0.04586612433195114\n",
      "150 0.05027087405323982\n",
      "151 0.0474860742688179\n",
      "152 0.046550020575523376\n",
      "153 0.0515776053071022\n",
      "154 0.04952223226428032\n",
      "155 0.0448119230568409\n",
      "156 0.0445745475590229\n",
      "157 0.04758295789361\n",
      "158 0.04460681229829788\n",
      "159 0.04292929917573929\n",
      "160 0.04239567369222641\n",
      "161 0.04326513037085533\n",
      "162 0.049940288066864014\n",
      "163 0.04270511493086815\n",
      "164 0.04041960462927818\n",
      "165 0.04542974755167961\n",
      "166 0.04877549409866333\n",
      "167 0.04362596571445465\n",
      "168 0.045491766184568405\n",
      "169 0.041592929512262344\n",
      "170 0.0445190891623497\n",
      "171 0.04559062048792839\n",
      "172 0.04639357328414917\n",
      "173 0.04698478430509567\n",
      "174 0.04280751571059227\n",
      "175 0.044834867119789124\n",
      "176 0.04310265928506851\n",
      "177 0.04101594164967537\n",
      "178 0.04530034586787224\n",
      "179 0.04256115481257439\n",
      "180 0.04171615093946457\n",
      "181 0.04837511479854584\n",
      "182 0.042418889701366425\n",
      "183 0.04824830964207649\n",
      "184 0.046263158321380615\n",
      "185 0.04541894420981407\n",
      "186 0.048721592873334885\n",
      "187 0.049167465418577194\n",
      "188 0.04885830357670784\n",
      "189 0.050333909690380096\n",
      "190 0.05123249813914299\n",
      "191 0.050728484988212585\n",
      "192 0.05088680237531662\n",
      "193 0.05189571529626846\n",
      "194 0.05035921186208725\n",
      "195 0.04796323925256729\n",
      "196 0.04953077808022499\n",
      "197 0.049969784915447235\n",
      "198 0.05025419965386391\n",
      "199 0.04820309206843376\n",
      "200 0.049092330038547516\n",
      "201 0.04912200942635536\n",
      "202 0.05258187651634216\n",
      "203 0.049991004168987274\n",
      "204 0.04718447104096413\n",
      "205 0.04439181461930275\n",
      "206 0.05070900171995163\n",
      "207 0.048612143844366074\n",
      "208 0.049913860857486725\n",
      "209 0.05033303052186966\n",
      "210 0.04894915223121643\n",
      "211 0.048904918134212494\n",
      "212 0.04951874911785126\n",
      "213 0.04873914271593094\n",
      "214 0.04581615701317787\n",
      "215 0.05073070898652077\n",
      "216 0.05224945768713951\n",
      "217 0.04386566951870918\n",
      "218 0.04621533676981926\n",
      "219 0.04727049544453621\n",
      "220 0.0433398112654686\n",
      "221 0.04565730318427086\n",
      "222 0.04957958310842514\n",
      "223 0.05056137591600418\n",
      "224 0.046367596834897995\n",
      "225 0.048129111528396606\n",
      "226 0.04470627382397652\n",
      "227 0.045473579317331314\n",
      "228 0.045679185539484024\n",
      "229 0.04902305081486702\n",
      "230 0.04847715422511101\n",
      "231 0.04719860851764679\n",
      "232 0.048306096345186234\n",
      "233 0.04733288660645485\n",
      "234 0.04589303582906723\n",
      "235 0.0463964119553566\n",
      "236 0.05184636265039444\n",
      "237 0.047686755657196045\n",
      "238 0.04815424978733063\n",
      "239 0.046496566385030746\n",
      "240 0.04831768572330475\n",
      "241 0.04586343094706535\n",
      "242 0.04784296452999115\n",
      "243 0.049190912395715714\n",
      "244 0.04743523150682449\n",
      "245 0.05023787543177605\n",
      "246 0.0486709326505661\n",
      "247 0.048513058573007584\n",
      "248 0.044876113533973694\n",
      "249 0.049825623631477356\n",
      "250 0.046911049634218216\n",
      "251 0.04803498461842537\n",
      "252 0.049876801669597626\n",
      "253 0.04636484757065773\n",
      "254 0.04596632719039917\n",
      "255 0.048490382730960846\n",
      "256 0.04571060836315155\n",
      "257 0.04727967828512192\n",
      "258 0.0457860603928566\n",
      "259 0.046971987932920456\n",
      "260 0.045297086238861084\n",
      "261 0.045755669474601746\n",
      "262 0.04599112644791603\n",
      "263 0.0463847778737545\n",
      "264 0.04821073263883591\n",
      "265 0.05119787156581879\n",
      "266 0.04669005423784256\n",
      "267 0.04560185596346855\n",
      "268 0.047083377838134766\n",
      "269 0.04644026607275009\n",
      "270 0.046480823308229446\n",
      "271 0.04787323251366615\n",
      "272 0.04665744677186012\n",
      "273 0.04736807569861412\n",
      "274 0.04731643572449684\n",
      "275 0.05181659013032913\n",
      "276 0.043731555342674255\n",
      "277 0.04397115483880043\n",
      "278 0.04632958397269249\n",
      "279 0.04683465510606766\n",
      "280 0.04696741700172424\n",
      "281 0.053341761231422424\n",
      "282 0.04873399809002876\n",
      "283 0.04598062112927437\n",
      "284 0.04821520671248436\n",
      "285 0.04938685894012451\n",
      "286 0.0454392284154892\n",
      "287 0.054917704313993454\n",
      "288 0.04887496680021286\n",
      "289 0.0471130795776844\n",
      "290 0.05031505227088928\n",
      "291 0.05150262266397476\n",
      "292 0.051190126687288284\n",
      "293 0.04778679087758064\n",
      "294 0.04466923698782921\n",
      "295 0.05012241378426552\n",
      "296 0.051420167088508606\n",
      "297 0.05075022578239441\n",
      "298 0.048914145678281784\n",
      "299 0.04644715413451195\n",
      "300 0.049167972058057785\n",
      "301 0.051267109811306\n",
      "302 0.047074396163225174\n",
      "303 0.048532579094171524\n",
      "304 0.04831269755959511\n",
      "305 0.04912888631224632\n",
      "306 0.050936926156282425\n",
      "307 0.04808655008673668\n",
      "308 0.04891255497932434\n",
      "309 0.04854987561702728\n",
      "310 0.04978599771857262\n",
      "311 0.04796754941344261\n",
      "312 0.04850956052541733\n",
      "313 0.048361990600824356\n",
      "314 0.04868695139884949\n",
      "315 0.04654824733734131\n",
      "316 0.04868762567639351\n",
      "317 0.04603049159049988\n",
      "318 0.047990910708904266\n",
      "319 0.04649891331791878\n",
      "320 0.04428649693727493\n",
      "321 0.0469118095934391\n",
      "322 0.05130027234554291\n",
      "323 0.051204945892095566\n",
      "324 0.04837509244680405\n",
      "325 0.04414338991045952\n",
      "326 0.04554417356848717\n",
      "327 0.04702266678214073\n",
      "328 0.04889492318034172\n",
      "329 0.04759617894887924\n",
      "330 0.04560356214642525\n",
      "331 0.04524146765470505\n",
      "332 0.05111733078956604\n",
      "333 0.04851545765995979\n",
      "334 0.04830164462327957\n",
      "335 0.044987551867961884\n",
      "336 0.048461198806762695\n",
      "337 0.04911423847079277\n",
      "338 0.045200929045677185\n",
      "339 0.045876163989305496\n",
      "340 0.04561477154493332\n",
      "341 0.04551462456583977\n",
      "342 0.045518502593040466\n",
      "343 0.045573703944683075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 0.04733552411198616\n",
      "345 0.04731189087033272\n",
      "346 0.04863543435931206\n",
      "347 0.04986785724759102\n",
      "348 0.046485304832458496\n",
      "349 0.045285362750291824\n",
      "350 0.04387057200074196\n",
      "351 0.04827858507633209\n",
      "352 0.045822951942682266\n",
      "353 0.044787198305130005\n",
      "354 0.04568511247634888\n",
      "355 0.043563976883888245\n",
      "356 0.04339488968253136\n",
      "357 0.04518371820449829\n",
      "358 0.04471335932612419\n",
      "359 0.04785897210240364\n",
      "360 0.04757748544216156\n",
      "361 0.046178046613931656\n",
      "362 0.046913884580135345\n",
      "363 0.04420328885316849\n",
      "364 0.04619733244180679\n",
      "365 0.04993663355708122\n",
      "366 0.04496149346232414\n",
      "367 0.047340746968984604\n",
      "368 0.05094803497195244\n",
      "369 0.04774472489953041\n",
      "370 0.04521750286221504\n",
      "371 0.0464811846613884\n",
      "372 0.04678346589207649\n",
      "373 0.04572725668549538\n",
      "374 0.04608190059661865\n",
      "375 0.04847012832760811\n",
      "376 0.047918159514665604\n",
      "377 0.045605968683958054\n",
      "378 0.04420149326324463\n",
      "379 0.04516441002488136\n",
      "380 0.045572903007268906\n",
      "381 0.04782181605696678\n",
      "382 0.046306610107421875\n",
      "383 0.04603544622659683\n",
      "384 0.04853209853172302\n",
      "385 0.04563385248184204\n",
      "386 0.04596290364861488\n",
      "387 0.047426510602235794\n",
      "388 0.045283909887075424\n",
      "389 0.045387186110019684\n",
      "390 0.04598912224173546\n",
      "391 0.04652119800448418\n",
      "392 0.04878246784210205\n",
      "393 0.04669112339615822\n",
      "394 0.04536806792020798\n",
      "395 0.04481542482972145\n",
      "396 0.047898195683956146\n",
      "397 0.041779305785894394\n",
      "398 0.04675242677330971\n",
      "399 0.04709196835756302\n",
      "400 0.04347572475671768\n",
      "401 0.04730848968029022\n",
      "402 0.04602441564202309\n",
      "403 0.047539036720991135\n",
      "404 0.0448157861828804\n",
      "405 0.043486762791872025\n",
      "406 0.04561493173241615\n",
      "407 0.04259096831083298\n",
      "408 0.04741067811846733\n",
      "409 0.04632046818733215\n",
      "410 0.047524504363536835\n",
      "411 0.04593846946954727\n",
      "412 0.04615454003214836\n",
      "413 0.046165864914655685\n",
      "414 0.04147136211395264\n",
      "415 0.045904163271188736\n",
      "416 0.04482725262641907\n",
      "417 0.04616696387529373\n",
      "418 0.04504382982850075\n",
      "419 0.04399162903428078\n",
      "420 0.047083865851163864\n",
      "421 0.045766137540340424\n",
      "422 0.04950251057744026\n",
      "423 0.04593107849359512\n",
      "424 0.04730992019176483\n",
      "425 0.04681987687945366\n",
      "426 0.04670987278223038\n",
      "427 0.047818902879953384\n",
      "428 0.04558146372437477\n",
      "429 0.04621436446905136\n",
      "430 0.049825090914964676\n",
      "431 0.04847998544573784\n",
      "432 0.04886958748102188\n",
      "433 0.04898795112967491\n",
      "434 0.0533929206430912\n",
      "435 0.04850031062960625\n",
      "436 0.045628391206264496\n",
      "437 0.05297804996371269\n",
      "438 0.05279193073511124\n",
      "439 0.049452491104602814\n",
      "440 0.048246774822473526\n",
      "441 0.046470414847135544\n",
      "442 0.05009391903877258\n",
      "443 0.05065705627202988\n",
      "444 0.04807976633310318\n",
      "445 0.049048442393541336\n",
      "446 0.05219780653715134\n",
      "447 0.05405258387327194\n",
      "448 0.05075320228934288\n",
      "449 0.05326201766729355\n",
      "450 0.048902563750743866\n",
      "451 0.05030076205730438\n",
      "452 0.04877845570445061\n",
      "453 0.049408186227083206\n",
      "454 0.04699727147817612\n",
      "455 0.049245573580265045\n",
      "456 0.048966411501169205\n",
      "457 0.0505329854786396\n",
      "458 0.050645262002944946\n",
      "459 0.0488770566880703\n",
      "460 0.04759812355041504\n",
      "461 0.048569537699222565\n",
      "462 0.051149364560842514\n",
      "463 0.052686359733343124\n",
      "464 0.051372773945331573\n",
      "465 0.050750017166137695\n",
      "466 0.04847220703959465\n",
      "467 0.047852225601673126\n",
      "468 0.048938632011413574\n",
      "469 0.047892604023218155\n",
      "470 0.049559421837329865\n",
      "471 0.04702401161193848\n",
      "472 0.04895654320716858\n",
      "473 0.050646744668483734\n",
      "474 0.04691013693809509\n",
      "475 0.0498347133398056\n",
      "476 0.04659980535507202\n",
      "477 0.04709282144904137\n",
      "478 0.050803348422050476\n",
      "479 0.05119454860687256\n",
      "480 0.05053887888789177\n",
      "481 0.050983771681785583\n",
      "482 0.04776014760136604\n",
      "483 0.05147816985845566\n",
      "484 0.0527220293879509\n",
      "485 0.048429977148771286\n",
      "486 0.05086999014019966\n",
      "487 0.05124344304203987\n",
      "488 0.048146385699510574\n",
      "489 0.048209935426712036\n",
      "490 0.05016566067934036\n",
      "491 0.04831770062446594\n",
      "492 0.04887593537569046\n",
      "493 0.048215631395578384\n",
      "494 0.04691621661186218\n",
      "495 0.04648733511567116\n",
      "496 0.045322973281145096\n",
      "497 0.045957282185554504\n",
      "498 0.046148594468832016\n",
      "499 0.05099153891205788\n",
      "500 0.05223141983151436\n",
      "501 0.04901791363954544\n",
      "502 0.04801853373646736\n",
      "503 0.045559968799352646\n",
      "504 0.046636223793029785\n",
      "505 0.04547993093729019\n",
      "506 0.04985152557492256\n",
      "507 0.051980338990688324\n",
      "508 0.04487917199730873\n",
      "509 0.049266014248132706\n",
      "510 0.0494573749601841\n",
      "511 0.04869217798113823\n",
      "512 0.04793158546090126\n",
      "513 0.04798339307308197\n",
      "514 0.04596865922212601\n",
      "515 0.052177462726831436\n",
      "516 0.04669690504670143\n",
      "517 0.04659274220466614\n",
      "518 0.044888101518154144\n",
      "519 0.046893246471881866\n",
      "520 0.0502513162791729\n",
      "521 0.04960072040557861\n",
      "522 0.049265991896390915\n",
      "done\n",
      "0.1252962048491075\n",
      "0.04679394516217777\n",
      "0.015845700159996576\n",
      "0.27068322780141413\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
