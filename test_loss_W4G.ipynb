{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_W4G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 13 20:48:20 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.23.04    Driver Version: 455.23.04    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:19:00.0 Off |                  N/A |\r\n",
      "| 75%   64C    P2   271W / 370W |  12878MiB / 24268MiB |     57%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:68:00.0 Off |                  N/A |\r\n",
      "| 67%   80C    P2   286W / 350W |  12431MiB / 24265MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     10604      C   ...conda3/envs/ai/bin/python    11895MiB |\r\n",
      "|    0   N/A  N/A     17012      C   ...conda3/envs/ai/bin/python      981MiB |\r\n",
      "|    1   N/A  N/A      4501      C   ...conda3/envs/ai/bin/python    12429MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'save/model_W4G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json   save_20000\tsave_40000  save_55000\tsave_70000  save_85000\r\n",
      "save_0\t    save_25000\tsave_45000  save_58657\tsave_75000  save_85150\r\n",
      "save_10000  save_30000\tsave_5000   save_60000\tsave_80000  save_90000\r\n",
      "save_15000  save_35000\tsave_50000  save_65000\tsave_82879  save_95000\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 124.1MiB\n",
      "TTS size 36.5MiB\n",
      "MelDecoder size 22.9MiB\n",
      "loaded : 95000\n",
      "95000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 95000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f74f0d9fd90>\n"
     ]
    }
   ],
   "source": [
    "testset = LJDataset(tts_hparams, split='test')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05051849037408829\n",
      "1 0.05046040192246437\n",
      "2 0.04937683045864105\n",
      "3 0.0468469113111496\n",
      "4 0.05073393136262894\n",
      "5 0.04750362038612366\n",
      "6 0.048118092119693756\n",
      "7 0.049034588038921356\n",
      "8 0.04871154576539993\n",
      "9 0.049938857555389404\n",
      "10 0.04947817325592041\n",
      "11 0.045689281076192856\n",
      "12 0.046406496316194534\n",
      "13 0.052509941160678864\n",
      "14 0.04731038212776184\n",
      "15 0.05133011192083359\n",
      "16 0.05782129615545273\n",
      "17 0.04817279055714607\n",
      "18 0.05089019984006882\n",
      "19 0.04777495935559273\n",
      "20 0.05020926892757416\n",
      "21 0.04995884373784065\n",
      "22 0.04550570622086525\n",
      "23 0.05027031525969505\n",
      "24 0.04870418459177017\n",
      "25 0.04783337563276291\n",
      "26 0.04773690924048424\n",
      "27 0.04534708335995674\n",
      "28 0.050113532692193985\n",
      "29 0.04902051389217377\n",
      "30 0.04929393157362938\n",
      "31 0.05014122650027275\n",
      "32 0.048422038555145264\n",
      "33 0.04685681685805321\n",
      "34 0.05223092436790466\n",
      "35 0.04868811368942261\n",
      "36 0.04824455454945564\n",
      "37 0.049792446196079254\n",
      "38 0.04826692119240761\n",
      "39 0.04556838050484657\n",
      "40 0.047954071313142776\n",
      "41 0.04925279691815376\n",
      "42 0.05215505510568619\n",
      "43 0.05337076261639595\n",
      "44 0.05145583674311638\n",
      "45 0.047073546797037125\n",
      "46 0.04719698056578636\n",
      "47 0.04734913259744644\n",
      "48 0.04806693643331528\n",
      "49 0.04221733286976814\n",
      "50 0.04828517138957977\n",
      "51 0.04770691692829132\n",
      "52 0.04930080473423004\n",
      "53 0.048207927495241165\n",
      "54 0.052057161927223206\n",
      "55 0.04662962257862091\n",
      "56 0.04626285657286644\n",
      "57 0.054561350494623184\n",
      "58 0.0469101257622242\n",
      "59 0.04894106835126877\n",
      "60 0.045349109917879105\n",
      "61 0.04951590299606323\n",
      "62 0.04841763153672218\n",
      "63 0.0479932501912117\n",
      "64 0.04732783883810043\n",
      "65 0.04917516931891441\n",
      "66 0.04328488931059837\n",
      "67 0.0471552312374115\n",
      "68 0.04855393245816231\n",
      "69 0.046110834926366806\n",
      "70 0.05115154758095741\n",
      "71 0.04816964641213417\n",
      "72 0.047430869191884995\n",
      "73 0.04789458215236664\n",
      "74 0.044605955481529236\n",
      "75 0.04860221594572067\n",
      "76 0.04916932061314583\n",
      "77 0.04750079661607742\n",
      "78 0.04598936438560486\n",
      "79 0.04452291876077652\n",
      "80 0.04867943376302719\n",
      "81 0.04773383215069771\n",
      "82 0.046560462564229965\n",
      "83 0.046736568212509155\n",
      "84 0.0458846352994442\n",
      "85 0.046642448753118515\n",
      "86 0.04619744420051575\n",
      "87 0.046734027564525604\n",
      "88 0.04582825303077698\n",
      "89 0.04694940894842148\n",
      "90 0.04832157492637634\n",
      "91 0.05144141986966133\n",
      "92 0.04876455292105675\n",
      "93 0.048898760229349136\n",
      "94 0.04497284069657326\n",
      "95 0.047508757561445236\n",
      "96 0.04757167026400566\n",
      "97 0.04733403027057648\n",
      "98 0.044315773993730545\n",
      "99 0.04478977248072624\n",
      "100 0.04637743905186653\n",
      "101 0.044078271836042404\n",
      "102 0.04561269283294678\n",
      "103 0.047575633972883224\n",
      "104 0.045761946588754654\n",
      "105 0.04383546859025955\n",
      "106 0.047148216515779495\n",
      "107 0.04632965102791786\n",
      "108 0.051512349396944046\n",
      "109 0.046838365495204926\n",
      "110 0.04371938854455948\n",
      "111 0.046051766723394394\n",
      "112 0.04669606313109398\n",
      "113 0.04602769762277603\n",
      "114 0.04422037675976753\n",
      "115 0.04442232474684715\n",
      "116 0.04305880144238472\n",
      "117 0.04648146033287048\n",
      "118 0.04444579407572746\n",
      "119 0.04496340453624725\n",
      "120 0.04609185457229614\n",
      "121 0.04519716277718544\n",
      "122 0.04714152216911316\n",
      "123 0.046927403658628464\n",
      "124 0.04479853808879852\n",
      "125 0.04568016901612282\n",
      "126 0.0439809150993824\n",
      "127 0.04314466565847397\n",
      "128 0.04123837500810623\n",
      "129 0.04144207015633583\n",
      "130 0.04472474753856659\n",
      "131 0.0449724979698658\n",
      "132 0.04715821519494057\n",
      "133 0.048194486647844315\n",
      "134 0.04835103452205658\n",
      "135 0.041259802877902985\n",
      "136 0.04414230212569237\n",
      "137 0.046715401113033295\n",
      "138 0.04217878356575966\n",
      "139 0.04281012341380119\n",
      "140 0.04877878352999687\n",
      "141 0.04955103248357773\n",
      "142 0.05081586912274361\n",
      "143 0.04830099642276764\n",
      "144 0.04894553869962692\n",
      "145 0.04765855520963669\n",
      "146 0.04556269571185112\n",
      "147 0.04442288354039192\n",
      "148 0.04556318745017052\n",
      "149 0.04539423808455467\n",
      "150 0.04807156324386597\n",
      "151 0.04709913954138756\n",
      "152 0.04568894952535629\n",
      "153 0.04602309316396713\n",
      "154 0.04509668052196503\n",
      "155 0.04466390237212181\n",
      "156 0.04414347559213638\n",
      "157 0.04508271813392639\n",
      "158 0.04384440928697586\n",
      "159 0.043905485421419144\n",
      "160 0.04239099845290184\n",
      "161 0.04257189482450485\n",
      "162 0.04339056834578514\n",
      "163 0.04540524631738663\n",
      "164 0.04402900114655495\n",
      "165 0.04695640131831169\n",
      "166 0.04373406991362572\n",
      "167 0.04633226990699768\n",
      "168 0.04615673050284386\n",
      "169 0.04433027282357216\n",
      "170 0.04501050338149071\n",
      "171 0.04431043937802315\n",
      "172 0.04548140615224838\n",
      "173 0.040475815534591675\n",
      "174 0.047221772372722626\n",
      "175 0.04365373030304909\n",
      "176 0.04562908038496971\n",
      "177 0.045272164046764374\n",
      "178 0.0445074737071991\n",
      "179 0.04653109610080719\n",
      "180 0.04563385620713234\n",
      "181 0.045491818338632584\n",
      "182 0.04606092348694801\n",
      "183 0.04458427429199219\n",
      "184 0.044066306203603745\n",
      "185 0.04380599781870842\n",
      "186 0.04488176479935646\n",
      "187 0.04458330571651459\n",
      "188 0.04260339215397835\n",
      "189 0.04734307527542114\n",
      "190 0.04572494700551033\n",
      "191 0.04563229903578758\n",
      "192 0.04627838730812073\n",
      "193 0.04293539375066757\n",
      "194 0.04549851268529892\n",
      "195 0.04211954399943352\n",
      "196 0.046251080930233\n",
      "197 0.04440191015601158\n",
      "198 0.043734487146139145\n",
      "199 0.04283152520656586\n",
      "200 0.04157063737511635\n",
      "201 0.04302310571074486\n",
      "202 0.04330991581082344\n",
      "203 0.04230809584259987\n",
      "204 0.04656650498509407\n",
      "205 0.04623107984662056\n",
      "206 0.0487532913684845\n",
      "207 0.04457537457346916\n",
      "208 0.045243166387081146\n",
      "209 0.04219060763716698\n",
      "210 0.04510219767689705\n",
      "211 0.04530223459005356\n",
      "212 0.04317450523376465\n",
      "213 0.04279694706201553\n",
      "214 0.04386616870760918\n",
      "215 0.04399017617106438\n",
      "216 0.04366940259933472\n",
      "217 0.044513337314128876\n",
      "218 0.045422621071338654\n",
      "219 0.041999585926532745\n",
      "220 0.046414218842983246\n",
      "221 0.04233703389763832\n",
      "222 0.041401881724596024\n",
      "223 0.04127853736281395\n",
      "224 0.04939963296055794\n",
      "225 0.04614979401230812\n",
      "226 0.045636408030986786\n",
      "227 0.043389830738306046\n",
      "228 0.04400474950671196\n",
      "229 0.04596104100346565\n",
      "230 0.04524754732847214\n",
      "231 0.04430710896849632\n",
      "232 0.04235439747571945\n",
      "233 0.044492751359939575\n",
      "234 0.04301101341843605\n",
      "235 0.04576000198721886\n",
      "236 0.04317815601825714\n",
      "237 0.041589003056287766\n",
      "238 0.04567668214440346\n",
      "239 0.04624738171696663\n",
      "240 0.04650721326470375\n",
      "241 0.04579196497797966\n",
      "242 0.04480436444282532\n",
      "243 0.047596413642168045\n",
      "244 0.0451696552336216\n",
      "245 0.047387879341840744\n",
      "246 0.04377675801515579\n",
      "247 0.0425272174179554\n",
      "248 0.04154247045516968\n",
      "249 0.044650815427303314\n",
      "250 0.04316634312272072\n",
      "251 0.04001191258430481\n",
      "252 0.04835595563054085\n",
      "253 0.04330902919173241\n",
      "254 0.044644538313150406\n",
      "255 0.04291243106126785\n",
      "256 0.043697748333215714\n",
      "257 0.04591916874051094\n",
      "258 0.044612057507038116\n",
      "259 0.04395969212055206\n",
      "260 0.046804558485746384\n",
      "261 0.042137421667575836\n",
      "262 0.04669348895549774\n",
      "263 0.046715494245290756\n",
      "264 0.04794836416840553\n",
      "265 0.04268469288945198\n",
      "266 0.048863478004932404\n",
      "267 0.046744294464588165\n",
      "268 0.044498417526483536\n",
      "269 0.045175544917583466\n",
      "270 0.047415006905794144\n",
      "271 0.045930467545986176\n",
      "272 0.04647982865571976\n",
      "273 0.043996863067150116\n",
      "274 0.043511468917131424\n",
      "275 0.046719156205654144\n",
      "276 0.04314451292157173\n",
      "277 0.04577159509062767\n",
      "278 0.04551858827471733\n",
      "279 0.041313864290714264\n",
      "280 0.0413622111082077\n",
      "281 0.043173134326934814\n",
      "282 0.04404200613498688\n",
      "283 0.045189883559942245\n",
      "284 0.04529472440481186\n",
      "285 0.044481124728918076\n",
      "286 0.04609649255871773\n",
      "287 0.04602973535656929\n",
      "288 0.04548138752579689\n",
      "289 0.04350046440958977\n",
      "290 0.04586327448487282\n",
      "291 0.045484013855457306\n",
      "292 0.04541323706507683\n",
      "293 0.04569588229060173\n",
      "294 0.04790874198079109\n",
      "295 0.041003238409757614\n",
      "296 0.04613056406378746\n",
      "297 0.04342493414878845\n",
      "298 0.042503103613853455\n",
      "299 0.04450778290629387\n",
      "300 0.041476257145404816\n",
      "301 0.04526771977543831\n",
      "302 0.04390154033899307\n",
      "303 0.04836373031139374\n",
      "304 0.04290720075368881\n",
      "305 0.0409478135406971\n",
      "306 0.043108124285936356\n",
      "307 0.040858056396245956\n",
      "308 0.04379093274474144\n",
      "309 0.047486502677202225\n",
      "310 0.041981685906648636\n",
      "311 0.043206166476011276\n",
      "312 0.044717174023389816\n",
      "313 0.043361544609069824\n",
      "314 0.045119185000658035\n",
      "315 0.04215991869568825\n",
      "316 0.040681224316358566\n",
      "317 0.04385370761156082\n",
      "318 0.04375135526061058\n",
      "319 0.04375336691737175\n",
      "320 0.04225241392850876\n",
      "321 0.04169215261936188\n",
      "322 0.04839899018406868\n",
      "323 0.0426250658929348\n",
      "324 0.044147294014692307\n",
      "325 0.047395724803209305\n",
      "326 0.043341681361198425\n",
      "327 0.04263089597225189\n",
      "328 0.0432296022772789\n",
      "329 0.043834488838911057\n",
      "330 0.04564814269542694\n",
      "331 0.04743875190615654\n",
      "332 0.046390991657972336\n",
      "333 0.04405803978443146\n",
      "334 0.041904643177986145\n",
      "335 0.043733321130275726\n",
      "336 0.04273957014083862\n",
      "337 0.04718365892767906\n",
      "338 0.04288064315915108\n",
      "339 0.043081555515527725\n",
      "340 0.04476599022746086\n",
      "341 0.04264785721898079\n",
      "342 0.043392524123191833\n",
      "343 0.04243822023272514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 0.0437898263335228\n",
      "345 0.04034622386097908\n",
      "346 0.043044958263635635\n",
      "347 0.04522157087922096\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "recon_losses = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045737755880958735\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(recon_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
