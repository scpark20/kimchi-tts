{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_S5G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 13 21:58:24 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:2E:00.0 Off |                  N/A |\r\n",
      "| 56%   65C    P2    96W / 250W |   1138MiB / 11016MiB |      7%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |\r\n",
      "| 52%   60C    P2    73W / 250W |    634MiB / 11019MiB |      8%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     21362      C   ...onda3/envs/vae/bin/python     1135MiB |\r\n",
      "|    1   N/A  N/A     21399      C   ...onda3/envs/vae/bin/python      631MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/model_S5G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_104221  save_123593  save_130000  save_75000\tsave_98268\r\n",
      "save_100000  save_105000  save_123671  save_132767  save_80000\tsave_98508\r\n",
      "save_100189  save_110000  save_123692  save_133754  save_85000\r\n",
      "save_100481  save_115000  save_125000  save_135000  save_90000\r\n",
      "save_100728  save_120000  save_128431  save_137981  save_95000\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 283.0MiB\n",
      "TTS size 195.3MiB\n",
      "MelDecoder size 119.0MiB\n",
      "loaded : 100000\n",
      "100000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 100000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7feca8343280>\n"
     ]
    }
   ],
   "source": [
    "testset = LJDataset(tts_hparams, split='test')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.054238639771938324\n",
      "1 0.05548226088285446\n",
      "2 0.05481388792395592\n",
      "3 0.049313537776470184\n",
      "4 0.05553204193711281\n",
      "5 0.050328329205513\n",
      "6 0.051741573959589005\n",
      "7 0.05133785307407379\n",
      "8 0.052792470902204514\n",
      "9 0.05060416832566261\n",
      "10 0.05493341013789177\n",
      "11 0.04925775155425072\n",
      "12 0.048077184706926346\n",
      "13 0.053336337208747864\n",
      "14 0.05012590438127518\n",
      "15 0.055695295333862305\n",
      "16 0.058303095400333405\n",
      "17 0.05095816031098366\n",
      "18 0.050051622092723846\n",
      "19 0.05093294382095337\n",
      "20 0.05248141661286354\n",
      "21 0.06291216611862183\n",
      "22 0.04887690022587776\n",
      "23 0.05346674099564552\n",
      "24 0.05205389857292175\n",
      "25 0.05104187875986099\n",
      "26 0.051297347992658615\n",
      "27 0.046963032335042953\n",
      "28 0.057194869965314865\n",
      "29 0.050954997539520264\n",
      "30 0.05279622972011566\n",
      "31 0.05351537466049194\n",
      "32 0.050626110285520554\n",
      "33 0.04942727088928223\n",
      "34 0.05219503864645958\n",
      "35 0.05340008810162544\n",
      "36 0.05295513570308685\n",
      "37 0.052949629724025726\n",
      "38 0.05130462348461151\n",
      "39 0.049308087676763535\n",
      "40 0.05057826265692711\n",
      "41 0.0526852123439312\n",
      "42 0.05403364077210426\n",
      "43 0.05562445893883705\n",
      "44 0.05437562242150307\n",
      "45 0.05078558996319771\n",
      "46 0.04974216967821121\n",
      "47 0.04970303177833557\n",
      "48 0.0509551465511322\n",
      "49 0.04616822674870491\n",
      "50 0.04865208640694618\n",
      "51 0.04925745353102684\n",
      "52 0.05267595127224922\n",
      "53 0.05236878618597984\n",
      "54 0.05655106529593468\n",
      "55 0.053091730922460556\n",
      "56 0.04965880885720253\n",
      "57 0.06356284022331238\n",
      "58 0.05064089596271515\n",
      "59 0.05351351201534271\n",
      "60 0.04857254773378372\n",
      "61 0.05076421797275543\n",
      "62 0.05147445574402809\n",
      "63 0.049827903509140015\n",
      "64 0.046301547437906265\n",
      "65 0.05508722737431526\n",
      "66 0.043493811041116714\n",
      "67 0.05029384046792984\n",
      "68 0.05448969826102257\n",
      "69 0.051315389573574066\n",
      "70 0.05215674266219139\n",
      "71 0.05308448150753975\n",
      "72 0.05021918937563896\n",
      "73 0.05646183714270592\n",
      "74 0.045802485197782516\n",
      "75 0.05124574154615402\n",
      "76 0.05233367905020714\n",
      "77 0.05015996843576431\n",
      "78 0.04890744760632515\n",
      "79 0.04603514075279236\n",
      "80 0.0528172068297863\n",
      "81 0.04959653690457344\n",
      "82 0.050608616322278976\n",
      "83 0.04944049194455147\n",
      "84 0.050144512206315994\n",
      "85 0.05247024819254875\n",
      "86 0.04968024417757988\n",
      "87 0.049742721021175385\n",
      "88 0.048911549150943756\n",
      "89 0.05029693990945816\n",
      "90 0.05369695648550987\n",
      "91 0.05665387585759163\n",
      "92 0.050975315272808075\n",
      "93 0.05247107148170471\n",
      "94 0.04916948452591896\n",
      "95 0.04925626143813133\n",
      "96 0.049582190811634064\n",
      "97 0.05167294666171074\n",
      "98 0.046474527567625046\n",
      "99 0.04710618406534195\n",
      "100 0.04915764555335045\n",
      "101 0.04804319143295288\n",
      "102 0.04644647613167763\n",
      "103 0.05103854835033417\n",
      "104 0.049166832119226456\n",
      "105 0.04505656659603119\n",
      "106 0.07255738973617554\n",
      "107 0.0486222468316555\n",
      "108 0.054901767522096634\n",
      "109 0.04798981547355652\n",
      "110 0.044390156865119934\n",
      "111 0.049129460006952286\n",
      "112 0.05222887545824051\n",
      "113 0.047457255423069\n",
      "114 0.04824699088931084\n",
      "115 0.048208896070718765\n",
      "116 0.04810447245836258\n",
      "117 0.0483788400888443\n",
      "118 0.046770647168159485\n",
      "119 0.0503714345395565\n",
      "120 0.047617070376873016\n",
      "121 0.047603242099285126\n",
      "122 0.05099499598145485\n",
      "123 0.04930056631565094\n",
      "124 0.04643174633383751\n",
      "125 0.04760602116584778\n",
      "126 0.04779902845621109\n",
      "127 0.044349554926157\n",
      "128 0.04214340075850487\n",
      "129 0.04562019556760788\n",
      "130 0.04849323630332947\n",
      "131 0.04793969914317131\n",
      "132 0.04828358069062233\n",
      "133 0.05032087489962578\n",
      "134 0.04858195409178734\n",
      "135 0.043870363384485245\n",
      "136 0.04677175357937813\n",
      "137 0.04916815087199211\n",
      "138 0.04557298496365547\n",
      "139 0.044923409819602966\n",
      "140 0.05321749299764633\n",
      "141 0.05489421263337135\n",
      "142 0.05522962287068367\n",
      "143 0.05024508014321327\n",
      "144 0.05253128707408905\n",
      "145 0.05101018399000168\n",
      "146 0.051569242030382156\n",
      "147 0.0479237325489521\n",
      "148 0.05060068145394325\n",
      "149 0.04776956886053085\n",
      "150 0.05045098066329956\n",
      "151 0.05184488371014595\n",
      "152 0.050333067774772644\n",
      "153 0.05087851360440254\n",
      "154 0.04737510904669762\n",
      "155 0.04640684276819229\n",
      "156 0.04600200802087784\n",
      "157 0.04917950928211212\n",
      "158 0.04606836289167404\n",
      "159 0.04711972549557686\n",
      "160 0.04531180486083031\n",
      "161 0.04675379768013954\n",
      "162 0.04738377407193184\n",
      "163 0.047738514840602875\n",
      "164 0.04858289286494255\n",
      "165 0.0490604005753994\n",
      "166 0.04721105098724365\n",
      "167 0.04970904067158699\n",
      "168 0.04893365502357483\n",
      "169 0.04919066280126572\n",
      "170 0.04809270426630974\n",
      "171 0.04712756723165512\n",
      "172 0.05136152356863022\n",
      "173 0.044255293905735016\n",
      "174 0.04876697063446045\n",
      "175 0.04541212320327759\n",
      "176 0.049246203154325485\n",
      "177 0.04833829775452614\n",
      "178 0.045864276587963104\n",
      "179 0.05209498852491379\n",
      "180 0.05011279881000519\n",
      "181 0.045548103749752045\n",
      "182 0.04676872491836548\n",
      "183 0.04674201086163521\n",
      "184 0.04616034775972366\n",
      "185 0.045947447419166565\n",
      "186 0.049355436116456985\n",
      "187 0.04610768333077431\n",
      "188 0.04421645775437355\n",
      "189 0.04825061932206154\n",
      "190 0.04845321178436279\n",
      "191 0.04803342744708061\n",
      "192 0.04744803532958031\n",
      "193 0.04476116970181465\n",
      "194 0.04726989567279816\n",
      "195 0.04512576386332512\n",
      "196 0.05346062034368515\n",
      "197 0.04667184129357338\n",
      "198 0.04639128968119621\n",
      "199 0.04621019959449768\n",
      "200 0.044810399413108826\n",
      "201 0.04572942107915878\n",
      "202 0.04612283781170845\n",
      "203 0.04496252164244652\n",
      "204 0.049203187227249146\n",
      "205 0.04827075079083443\n",
      "206 0.050797801464796066\n",
      "207 0.04753788560628891\n",
      "208 0.04704169183969498\n",
      "209 0.04422414302825928\n",
      "210 0.04801930487155914\n",
      "211 0.04638392850756645\n",
      "212 0.04783289507031441\n",
      "213 0.04485403373837471\n",
      "214 0.045779161155223846\n",
      "215 0.04449523612856865\n",
      "216 0.04548201709985733\n",
      "217 0.04880007356405258\n",
      "218 0.047201402485370636\n",
      "219 0.048724111169576645\n",
      "220 0.05024130642414093\n",
      "221 0.045019011944532394\n",
      "222 0.04219748079776764\n",
      "223 0.04313576593995094\n",
      "224 0.05254031717777252\n",
      "225 0.04772111400961876\n",
      "226 0.047574352473020554\n",
      "227 0.04653628543019295\n",
      "228 0.04681029170751572\n",
      "229 0.05110318586230278\n",
      "230 0.048905614763498306\n",
      "231 0.045621346682310104\n",
      "232 0.04524178057909012\n",
      "233 0.04753919318318367\n",
      "234 0.04518371820449829\n",
      "235 0.04969192296266556\n",
      "236 0.04606727510690689\n",
      "237 0.044479548931121826\n",
      "238 0.04936801642179489\n",
      "239 0.047879334539175034\n",
      "240 0.05274835601449013\n",
      "241 0.05050632730126381\n",
      "242 0.0485120452940464\n",
      "243 0.0523841492831707\n",
      "244 0.04815620929002762\n",
      "245 0.049864720553159714\n",
      "246 0.04709066450595856\n",
      "247 0.04682079702615738\n",
      "248 0.042639847844839096\n",
      "249 0.04977642372250557\n",
      "250 0.044756628572940826\n",
      "251 0.04183337092399597\n",
      "252 0.050718653947114944\n",
      "253 0.04392839968204498\n",
      "254 0.0478353276848793\n",
      "255 0.04708229750394821\n",
      "256 0.049275729805231094\n",
      "257 0.04652237892150879\n",
      "258 0.04762556776404381\n",
      "259 0.0463058166205883\n",
      "260 0.05293956771492958\n",
      "261 0.04491246119141579\n",
      "262 0.04937285929918289\n",
      "263 0.049728814512491226\n",
      "264 0.05079415440559387\n",
      "265 0.04401203244924545\n",
      "266 0.05373737961053848\n",
      "267 0.050440140068531036\n",
      "268 0.0463893860578537\n",
      "269 0.046563372015953064\n",
      "270 0.05041331797838211\n",
      "271 0.04992867261171341\n",
      "272 0.050245534628629684\n",
      "273 0.04724976792931557\n",
      "274 0.0463605672121048\n",
      "275 0.04970155656337738\n",
      "276 0.047222938388586044\n",
      "277 0.04975392296910286\n",
      "278 0.04913469776511192\n",
      "279 0.04490891844034195\n",
      "280 0.04405352845788002\n",
      "281 0.045157674700021744\n",
      "282 0.04724330082535744\n",
      "283 0.047838035970926285\n",
      "284 0.046957213431596756\n",
      "285 0.04421614855527878\n",
      "286 0.05012961104512215\n",
      "287 0.05057363584637642\n",
      "288 0.04854216054081917\n",
      "289 0.04554721340537071\n",
      "290 0.052436597645282745\n",
      "291 0.049565836787223816\n",
      "292 0.04881320521235466\n",
      "293 0.046758104115724564\n",
      "294 0.049910999834537506\n",
      "295 0.04544335603713989\n",
      "296 0.050891973078250885\n",
      "297 0.047466378659009933\n",
      "298 0.044168516993522644\n",
      "299 0.04738929867744446\n",
      "300 0.04575812816619873\n",
      "301 0.047049980610609055\n",
      "302 0.04808136075735092\n",
      "303 0.05043751746416092\n",
      "304 0.04444325715303421\n",
      "305 0.04390399158000946\n",
      "306 0.04842883348464966\n",
      "307 0.04531562700867653\n",
      "308 0.04768352583050728\n",
      "309 0.050163932144641876\n",
      "310 0.043458376079797745\n",
      "311 0.04675549641251564\n",
      "312 0.046843428164720535\n",
      "313 0.04537291079759598\n",
      "314 0.04696638137102127\n",
      "315 0.04440995305776596\n",
      "316 0.042309295386075974\n",
      "317 0.045317988842725754\n",
      "318 0.0444369874894619\n",
      "319 0.04672206938266754\n",
      "320 0.045142412185668945\n",
      "321 0.04508650302886963\n",
      "322 0.05321917310357094\n",
      "323 0.045047227293252945\n",
      "324 0.04676040634512901\n",
      "325 0.048552483320236206\n",
      "326 0.04666197672486305\n",
      "327 0.04400743171572685\n",
      "328 0.046821314841508865\n",
      "329 0.046643733978271484\n",
      "330 0.04712542146444321\n",
      "331 0.04736655205488205\n",
      "332 0.04848194867372513\n",
      "333 0.04670214280486107\n",
      "334 0.04397629201412201\n",
      "335 0.0473661944270134\n",
      "336 0.04523773491382599\n",
      "337 0.052817948162555695\n",
      "338 0.04688460752367973\n",
      "339 0.047766007483005524\n",
      "340 0.04564995318651199\n",
      "341 0.04597724229097366\n",
      "342 0.04661187529563904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 0.04319530725479126\n",
      "344 0.0455731600522995\n",
      "345 0.043707702308893204\n",
      "346 0.044133905321359634\n",
      "347 0.04946621134877205\n",
      "done\n",
      "0.075774136133762\n",
      "0.048824842665986766\n",
      "0.01528154366820965\n",
      "0.274776464991871\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
