{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from hparams.hparams_S5G import create_hparams\n",
    "from model import Model\n",
    "from datasets import LJDataset, TextMelCollate\n",
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 15 17:09:50 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:2E:00.0 Off |                  N/A |\r\n",
      "| 67%   80C    P2   116W / 250W |   1686MiB / 11016MiB |     27%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |\r\n",
      "| 49%   68C    P0    53W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     18103      C   ...onda3/envs/vae/bin/python     1683MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/data/save/model_S5G'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json    save_123671  save_145000  save_177763  save_205000  save_75000\r\n",
      "save_100000  save_123692  save_146358  save_180000  save_210000  save_80000\r\n",
      "save_100189  save_125000  save_147866  save_184582  save_215000  save_85000\r\n",
      "save_100481  save_128431  save_150000  save_185000  save_219392  save_90000\r\n",
      "save_100728  save_130000  save_151422  save_185146  save_220000  save_95000\r\n",
      "save_104221  save_132767  save_155000  save_190000  save_225000  save_98268\r\n",
      "save_105000  save_133754  save_160000  save_195000  save_228147  save_98508\r\n",
      "save_110000  save_135000  save_165000  save_196835  save_230000\r\n",
      "save_115000  save_137981  save_170000  save_199144  save_232353\r\n",
      "save_120000  save_138253  save_170017  save_200000  save_235000\r\n",
      "save_123593  save_140000  save_175000  save_201253  save_239735\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 283.0MiB\n",
      "TTS size 195.3MiB\n",
      "MelDecoder size 119.0MiB\n",
      "loaded : 200000\n",
      "200000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "stt_hparams, tts_hparams = create_hparams()\n",
    "model = Model(stt_hparams, tts_hparams, mode='train')\n",
    "model = model.cuda()\n",
    "step = 200000\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.parameters()))\n",
    "print(f\"TTS size {size}\")\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.tts.mel_decoder.parameters()))\n",
    "print(f\"MelDecoder size {size}\")\n",
    "\n",
    "if True:\n",
    "    model, _, _ = logger.load(step, model, None)\n",
    "print(step)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f4fc2dc3ee0>\n"
     ]
    }
   ],
   "source": [
    "testset = LJDataset(tts_hparams, split='valid')\n",
    "collate_fn = TextMelCollate(tts_hparams)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, num_workers=1, \n",
    "                          shuffle=False, sampler=None, batch_size=1, pin_memory=False,\n",
    "                          drop_last=True, collate_fn=collate_fn)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['text'] = batch['text'].cuda()\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda()\n",
    "    batch['mels'] = batch['mels'].cuda()\n",
    "    batch['mel_lengths'] = batch['mel_lengths'].cuda()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.055360015481710434\n",
      "1 0.053552135825157166\n",
      "2 0.05508439242839813\n",
      "3 0.056137412786483765\n",
      "4 0.05431392788887024\n",
      "5 0.05758911743760109\n",
      "6 0.06160475313663483\n",
      "7 0.05369510129094124\n",
      "8 0.056176479905843735\n",
      "9 0.05095161870121956\n",
      "10 0.05450725927948952\n",
      "11 0.05487013980746269\n",
      "12 0.052675072103738785\n",
      "13 0.054262734949588776\n",
      "14 0.049854032695293427\n",
      "15 0.05551094189286232\n",
      "16 0.06074507161974907\n",
      "17 0.06093020737171173\n",
      "18 0.05794273689389229\n",
      "19 0.05755509436130524\n",
      "20 0.0579526349902153\n",
      "21 0.05392006039619446\n",
      "22 0.054319337010383606\n",
      "23 0.054613299667835236\n",
      "24 0.061138980090618134\n",
      "25 0.06648078560829163\n",
      "26 0.054453495889902115\n",
      "27 0.05611124634742737\n",
      "28 0.057615846395492554\n",
      "29 0.05390026047825813\n",
      "30 0.05634808912873268\n",
      "31 0.05243983492255211\n",
      "32 0.05960921570658684\n",
      "33 0.052072349935770035\n",
      "34 0.0536082424223423\n",
      "35 0.05515662953257561\n",
      "36 0.049184199422597885\n",
      "37 0.059639569371938705\n",
      "38 0.05464186146855354\n",
      "39 0.0530659481883049\n",
      "40 0.06321576237678528\n",
      "41 0.05493394285440445\n",
      "42 0.05035127326846123\n",
      "43 0.04918043315410614\n",
      "44 0.04520424082875252\n",
      "45 0.05281490460038185\n",
      "46 0.056903209537267685\n",
      "47 0.05326489359140396\n",
      "48 0.04790039360523224\n",
      "49 0.05124811828136444\n",
      "50 0.05185776576399803\n",
      "51 0.05553474277257919\n",
      "52 0.05051562190055847\n",
      "53 0.05154411494731903\n",
      "54 0.05765599384903908\n",
      "55 0.05568584054708481\n",
      "56 0.05433646962046623\n",
      "57 0.05297769606113434\n",
      "58 0.05131004378199577\n",
      "59 0.05487613379955292\n",
      "60 0.05959637463092804\n",
      "61 0.055784277617931366\n",
      "62 0.053716614842414856\n",
      "63 0.05643763765692711\n",
      "64 0.05307599902153015\n",
      "65 0.05280347168445587\n",
      "66 0.05103905498981476\n",
      "67 0.058607012033462524\n",
      "68 0.051047272980213165\n",
      "69 0.055280495434999466\n",
      "70 0.060888245701789856\n",
      "71 0.051649246364831924\n",
      "72 0.048058927059173584\n",
      "73 0.06059139221906662\n",
      "74 0.06446393579244614\n",
      "75 0.04847308620810509\n",
      "76 0.05369206890463829\n",
      "77 0.05692484229803085\n",
      "78 0.05801082029938698\n",
      "79 0.05719355493783951\n",
      "80 0.05466606467962265\n",
      "81 0.05114230886101723\n",
      "82 0.05456344038248062\n",
      "83 0.057267673313617706\n",
      "84 0.05607530474662781\n",
      "85 0.05905785411596298\n",
      "86 0.059587351977825165\n",
      "87 0.05111624673008919\n",
      "88 0.053269289433956146\n",
      "89 0.06022442504763603\n",
      "90 0.05748467519879341\n",
      "91 0.05739932507276535\n",
      "92 0.04908624291419983\n",
      "93 0.05509575456380844\n",
      "94 0.05177963525056839\n",
      "95 0.052120640873909\n",
      "96 0.05409384146332741\n",
      "97 0.0551844984292984\n",
      "98 0.05223793536424637\n",
      "99 0.05694250762462616\n",
      "100 0.05164162069559097\n",
      "101 0.05217922851443291\n",
      "102 0.05083475261926651\n",
      "103 0.04960046708583832\n",
      "104 0.053630754351615906\n",
      "105 0.051781632006168365\n",
      "106 0.05710709095001221\n",
      "107 0.05242213234305382\n",
      "108 0.052501365542411804\n",
      "109 0.0540095679461956\n",
      "110 0.05148528516292572\n",
      "111 0.04989699646830559\n",
      "112 0.051863037049770355\n",
      "113 0.05919201299548149\n",
      "114 0.04980756714940071\n",
      "115 0.05138356611132622\n",
      "116 0.055970124900341034\n",
      "117 0.055867768824100494\n",
      "118 0.05191335827112198\n",
      "119 0.05346139892935753\n",
      "120 0.0560758002102375\n",
      "121 0.04846477508544922\n",
      "122 0.06153251975774765\n",
      "123 0.05646980553865433\n",
      "124 0.04806945100426674\n",
      "125 0.05243194103240967\n",
      "126 0.05210723727941513\n",
      "127 0.05727190524339676\n",
      "128 0.04990905150771141\n",
      "129 0.05115737020969391\n",
      "130 0.05427408590912819\n",
      "131 0.053137172013521194\n",
      "132 0.06626720726490021\n",
      "133 0.0646480843424797\n",
      "134 0.06915012001991272\n",
      "135 0.06461165100336075\n",
      "136 0.057128019630908966\n",
      "137 0.06510645896196365\n",
      "138 0.06891483068466187\n",
      "139 0.05868935585021973\n",
      "140 0.05546880513429642\n",
      "141 0.06905603408813477\n",
      "142 0.0576619952917099\n",
      "143 0.05917675048112869\n",
      "144 0.05421670898795128\n",
      "145 0.061517857015132904\n",
      "146 0.0540492981672287\n",
      "147 0.06306519359350204\n",
      "148 0.0578782856464386\n",
      "149 0.05575771629810333\n",
      "150 0.05996415391564369\n",
      "151 0.057887449860572815\n",
      "152 0.05527544394135475\n",
      "153 0.0645882859826088\n",
      "154 0.06287135928869247\n",
      "155 0.055475253611803055\n",
      "156 0.05556178465485573\n",
      "157 0.058996327221393585\n",
      "158 0.053351376205682755\n",
      "159 0.052635326981544495\n",
      "160 0.05026032775640488\n",
      "161 0.052391376346349716\n",
      "162 0.056796930730342865\n",
      "163 0.04928310215473175\n",
      "164 0.04889220371842384\n",
      "165 0.056184493005275726\n",
      "166 0.062007129192352295\n",
      "167 0.0515751987695694\n",
      "168 0.053746823221445084\n",
      "169 0.05205830559134483\n",
      "170 0.05425025522708893\n",
      "171 0.05418986454606056\n",
      "172 0.05486002191901207\n",
      "173 0.05941560119390488\n",
      "174 0.050512272864580154\n",
      "175 0.054768528789281845\n",
      "176 0.051007501780986786\n",
      "177 0.049094606190919876\n",
      "178 0.05462968349456787\n",
      "179 0.05051689222455025\n",
      "180 0.05183229595422745\n",
      "181 0.0590919628739357\n",
      "182 0.05282175540924072\n",
      "183 0.06153620034456253\n",
      "184 0.05749715864658356\n",
      "185 0.05575336515903473\n",
      "186 0.05327189713716507\n",
      "187 0.05507740005850792\n",
      "188 0.056766435503959656\n",
      "189 0.060386911034584045\n",
      "190 0.06096522882580757\n",
      "191 0.05774172767996788\n",
      "192 0.05822921544313431\n",
      "193 0.05686267092823982\n",
      "194 0.059399593621492386\n",
      "195 0.05472104623913765\n",
      "196 0.05503557622432709\n",
      "197 0.055354271084070206\n",
      "198 0.05994473770260811\n",
      "199 0.060932058840990067\n",
      "200 0.0570593886077404\n",
      "201 0.05875340476632118\n",
      "202 0.05752083286643028\n",
      "203 0.05763452127575874\n",
      "204 0.05664173141121864\n",
      "205 0.050771914422512054\n",
      "206 0.05819076672196388\n",
      "207 0.05887369439005852\n",
      "208 0.05438331887125969\n",
      "209 0.05620545521378517\n",
      "210 0.05444931238889694\n",
      "211 0.05532870814204216\n",
      "212 0.05669362097978592\n",
      "213 0.05764146149158478\n",
      "214 0.05257945880293846\n",
      "215 0.06120913103222847\n",
      "216 0.0594746470451355\n",
      "217 0.04820175841450691\n",
      "218 0.055001821368932724\n",
      "219 0.052124008536338806\n",
      "220 0.04948429763317108\n",
      "221 0.05253654718399048\n",
      "222 0.05832061916589737\n",
      "223 0.056614816188812256\n",
      "224 0.053853098303079605\n",
      "225 0.05505118519067764\n",
      "226 0.05160188674926758\n",
      "227 0.050931356847286224\n",
      "228 0.05221075564622879\n",
      "229 0.06220077723264694\n",
      "230 0.056973304599523544\n",
      "231 0.05494005233049393\n",
      "232 0.05666511133313179\n",
      "233 0.05721786245703697\n",
      "234 0.05359269678592682\n",
      "235 0.05642978847026825\n",
      "236 0.05911595746874809\n",
      "237 0.05482171103358269\n",
      "238 0.058693792670965195\n",
      "239 0.05659301206469536\n",
      "240 0.057799529284238815\n",
      "241 0.051755331456661224\n",
      "242 0.05922172963619232\n",
      "243 0.05984346196055412\n",
      "244 0.0574193000793457\n",
      "245 0.0606471449136734\n",
      "246 0.058312419801950455\n",
      "247 0.0566103421151638\n",
      "248 0.052999041974544525\n",
      "249 0.058469727635383606\n",
      "250 0.05261478200554848\n",
      "251 0.059862155467271805\n",
      "252 0.06150579825043678\n",
      "253 0.058081287890672684\n",
      "254 0.05533404275774956\n",
      "255 0.05795450881123543\n",
      "256 0.052595559507608414\n",
      "257 0.0553358718752861\n",
      "258 0.05513671413064003\n",
      "259 0.05551906302571297\n",
      "260 0.05522077903151512\n",
      "261 0.05504739657044411\n",
      "262 0.055426619946956635\n",
      "263 0.05580458417534828\n",
      "264 0.054119568318128586\n",
      "265 0.06026547774672508\n",
      "266 0.061513546854257584\n",
      "267 0.055375248193740845\n",
      "268 0.05388277396559715\n",
      "269 0.05886238068342209\n",
      "270 0.05553373694419861\n",
      "271 0.055548109114170074\n",
      "272 0.05845055729150772\n",
      "273 0.054597947746515274\n",
      "274 0.054035089910030365\n",
      "275 0.06452829390764236\n",
      "276 0.052208296954631805\n",
      "277 0.049080923199653625\n",
      "278 0.054083552211523056\n",
      "279 0.05453845486044884\n",
      "280 0.050484832376241684\n",
      "281 0.06528415530920029\n",
      "282 0.05619765818119049\n",
      "283 0.05486852303147316\n",
      "284 0.057193953543901443\n",
      "285 0.06050055846571922\n",
      "286 0.0506373755633831\n",
      "287 0.07333313673734665\n",
      "288 0.05970629304647446\n",
      "289 0.05308690667152405\n",
      "290 0.06066500023007393\n",
      "291 0.062235355377197266\n",
      "292 0.06583110988140106\n",
      "293 0.05907939374446869\n",
      "294 0.053352728486061096\n",
      "295 0.06138163059949875\n",
      "296 0.06103978306055069\n",
      "297 0.05851127952337265\n",
      "298 0.05733487755060196\n",
      "299 0.0587085522711277\n",
      "300 0.05751311779022217\n",
      "301 0.06187376007437706\n",
      "302 0.06095888838171959\n",
      "303 0.060441892594099045\n",
      "304 0.05734594166278839\n",
      "305 0.058874163776636124\n",
      "306 0.060355108231306076\n",
      "307 0.05430997908115387\n",
      "308 0.058779340237379074\n",
      "309 0.05750963091850281\n",
      "310 0.05894986540079117\n",
      "311 0.055496931076049805\n",
      "312 0.05516263097524643\n",
      "313 0.054829034954309464\n",
      "314 0.05658361688256264\n",
      "315 0.05698132514953613\n",
      "316 0.057017985731363297\n",
      "317 0.05558644235134125\n",
      "318 0.05661676824092865\n",
      "319 0.05565285310149193\n",
      "320 0.049853015691041946\n",
      "321 0.05534617602825165\n",
      "322 0.060879189521074295\n",
      "323 0.056240182369947433\n",
      "324 0.06111954152584076\n",
      "325 0.05350815877318382\n",
      "326 0.0521843247115612\n",
      "327 0.05838823691010475\n",
      "328 0.05877739191055298\n",
      "329 0.05584023892879486\n",
      "330 0.051322244107723236\n",
      "331 0.05387343466281891\n",
      "332 0.06119269132614136\n",
      "333 0.05804814025759697\n",
      "334 0.05601581931114197\n",
      "335 0.04959534853696823\n",
      "336 0.058571044355630875\n",
      "337 0.05838211253285408\n",
      "338 0.05550233647227287\n",
      "339 0.05117630958557129\n",
      "340 0.054394833743572235\n",
      "341 0.05230441316962242\n",
      "342 0.05248532444238663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 0.05254712328314781\n",
      "344 0.056176427751779556\n",
      "345 0.05591726303100586\n",
      "346 0.05744358152151108\n",
      "347 0.06076287478208542\n",
      "348 0.05237362161278725\n",
      "349 0.05329403281211853\n",
      "350 0.050966519862413406\n",
      "351 0.05878521874547005\n",
      "352 0.053727272897958755\n",
      "353 0.054442744702100754\n",
      "354 0.05451289936900139\n",
      "355 0.052459511905908585\n",
      "356 0.05328791216015816\n",
      "357 0.0536615364253521\n",
      "358 0.05119894817471504\n",
      "359 0.054957397282123566\n",
      "360 0.05504031851887703\n",
      "361 0.051629021763801575\n",
      "362 0.054395899176597595\n",
      "363 0.05013427138328552\n",
      "364 0.056110456585884094\n",
      "365 0.05895585939288139\n",
      "366 0.054290443658828735\n",
      "367 0.054786454886198044\n",
      "368 0.05810907483100891\n",
      "369 0.05533989146351814\n",
      "370 0.05611250922083855\n",
      "371 0.059923816472291946\n",
      "372 0.056331876665353775\n",
      "373 0.05623917281627655\n",
      "374 0.052947234362363815\n",
      "375 0.05636025592684746\n",
      "376 0.06006895750761032\n",
      "377 0.05161459371447563\n",
      "378 0.0520128533244133\n",
      "379 0.0525168851017952\n",
      "380 0.05468742921948433\n",
      "381 0.05898292735219002\n",
      "382 0.05364711582660675\n",
      "383 0.05615691840648651\n",
      "384 0.05473599210381508\n",
      "385 0.053219620138406754\n",
      "386 0.06040946766734123\n",
      "387 0.05703089386224747\n",
      "388 0.05587350204586983\n",
      "389 0.054229166358709335\n",
      "390 0.05414755269885063\n",
      "391 0.05652889609336853\n",
      "392 0.058929674327373505\n",
      "393 0.05713623762130737\n",
      "394 0.05472579225897789\n",
      "395 0.05106537416577339\n",
      "396 0.058029770851135254\n",
      "397 0.04891117289662361\n",
      "398 0.05493839085102081\n",
      "399 0.05658341571688652\n",
      "400 0.05206511542201042\n",
      "401 0.05446485057473183\n",
      "402 0.05720571056008339\n",
      "403 0.058810699731111526\n",
      "404 0.051854778081178665\n",
      "405 0.05068012326955795\n",
      "406 0.053988978266716\n",
      "407 0.05323835462331772\n",
      "408 0.05413421243429184\n",
      "409 0.05636141449213028\n",
      "410 0.05235593393445015\n",
      "411 0.05432440713047981\n",
      "412 0.05818581581115723\n",
      "413 0.053409840911626816\n",
      "414 0.04910663142800331\n",
      "415 0.0524800680577755\n",
      "416 0.05549836531281471\n",
      "417 0.054946690797805786\n",
      "418 0.056747835129499435\n",
      "419 0.053586456924676895\n",
      "420 0.05947079882025719\n",
      "421 0.05361068248748779\n",
      "422 0.05835539102554321\n",
      "423 0.05402746424078941\n",
      "424 0.0568147674202919\n",
      "425 0.05381236597895622\n",
      "426 0.056393928825855255\n",
      "427 0.0562000498175621\n",
      "428 0.05259126052260399\n",
      "429 0.051783617585897446\n",
      "430 0.06040031090378761\n",
      "431 0.05629809945821762\n",
      "432 0.054163601249456406\n",
      "433 0.059200920164585114\n",
      "434 0.06299272179603577\n",
      "435 0.055284369736909866\n",
      "436 0.05416800454258919\n",
      "437 0.05866343155503273\n",
      "438 0.0678352415561676\n",
      "439 0.06075067073106766\n",
      "440 0.05798128992319107\n",
      "441 0.0539412647485733\n",
      "442 0.05908386781811714\n",
      "443 0.05762522667646408\n",
      "444 0.05353718250989914\n",
      "445 0.05818663910031319\n",
      "446 0.06001336872577667\n",
      "447 0.06022893637418747\n",
      "448 0.06084630265831947\n",
      "449 0.06476633250713348\n",
      "450 0.05983097106218338\n",
      "451 0.05970209836959839\n",
      "452 0.05746126174926758\n",
      "453 0.0566176176071167\n",
      "454 0.05406554043292999\n",
      "455 0.05909936502575874\n",
      "456 0.05829665809869766\n",
      "457 0.06380192935466766\n",
      "458 0.058286819607019424\n",
      "459 0.058338820934295654\n",
      "460 0.05563640967011452\n",
      "461 0.05784419924020767\n",
      "462 0.06068277359008789\n",
      "463 0.06097167357802391\n",
      "464 0.06308962404727936\n",
      "465 0.05818740651011467\n",
      "466 0.05704634636640549\n",
      "467 0.05563127249479294\n",
      "468 0.05701526254415512\n",
      "469 0.05646743252873421\n",
      "470 0.058898892253637314\n",
      "471 0.05586306005716324\n",
      "472 0.05532003566622734\n",
      "473 0.05603894963860512\n",
      "474 0.05071013420820236\n",
      "475 0.054500821977853775\n",
      "476 0.05306258425116539\n",
      "477 0.053984325379133224\n",
      "478 0.05842906981706619\n",
      "479 0.060799770057201385\n",
      "480 0.06008739396929741\n",
      "481 0.058616217225790024\n",
      "482 0.052887603640556335\n",
      "483 0.058675140142440796\n",
      "484 0.0633295327425003\n",
      "485 0.05632661283016205\n",
      "486 0.06104578077793121\n",
      "487 0.057058073580265045\n",
      "488 0.05640251561999321\n",
      "489 0.05690516531467438\n",
      "490 0.06123329699039459\n",
      "491 0.05531914532184601\n",
      "492 0.0576636902987957\n",
      "493 0.05578306317329407\n",
      "494 0.05571848526597023\n",
      "495 0.05663411319255829\n",
      "496 0.053352151066064835\n",
      "497 0.05335621163249016\n",
      "498 0.05177220329642296\n",
      "499 0.0621911883354187\n",
      "500 0.05985569208860397\n",
      "501 0.061724286526441574\n",
      "502 0.0531434640288353\n",
      "503 0.052668359130620956\n",
      "504 0.05496636778116226\n",
      "505 0.05409296974539757\n",
      "506 0.059281665831804276\n",
      "507 0.060119789093732834\n",
      "508 0.054307322949171066\n",
      "509 0.058669596910476685\n",
      "510 0.06283984333276749\n",
      "511 0.05864250287413597\n",
      "512 0.05520229786634445\n",
      "513 0.05598264932632446\n",
      "514 0.050500817596912384\n",
      "515 0.062298763543367386\n",
      "516 0.056652333587408066\n",
      "517 0.05558203160762787\n",
      "518 0.056526437401771545\n",
      "519 0.053845155984163284\n",
      "520 0.05691014602780342\n",
      "521 0.055781904608011246\n",
      "522 0.05683528631925583\n",
      "done\n",
      "0.06648918878640887\n",
      "0.05601924308798281\n",
      "0.015337559547681312\n",
      "0.2616466878989914\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "ce_losses = []\n",
    "recon_losses = []\n",
    "kl_losses = []\n",
    "sample_stds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = to_cuda(batch)\n",
    "        stt_outputs, tts_outputs = model(batch)\n",
    "        ce_loss = stt_outputs['loss'].item()\n",
    "        recon_loss = tts_outputs['recon_loss'].item()\n",
    "        kl_loss = tts_outputs['kl_loss'].item()\n",
    "        print(i, recon_loss)\n",
    "        \n",
    "        ce_losses.append(ce_loss)\n",
    "        recon_losses.append(recon_loss)\n",
    "        kl_losses.append(kl_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        samples_list = []\n",
    "        for _ in range(10):\n",
    "            samples, _ = model.inference(batch['text'], batch['mels'].size(2), stt_outputs[\"alignments\"], temperature=1.0, clip=2)\n",
    "            samples_list.append(samples)\n",
    "        samples_list = torch.cat(samples_list, dim=0)\n",
    "        sample_std = torch.std(samples_list, dim=0).mean().item()\n",
    "        sample_stds.append(sample_std)\n",
    "            \n",
    "        \n",
    "print('done')\n",
    "\n",
    "print(np.mean(ce_losses))\n",
    "print(np.mean(recon_losses))\n",
    "print(np.mean(kl_losses))\n",
    "print(np.mean(sample_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
